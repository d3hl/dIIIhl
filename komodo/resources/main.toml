[[server]]
name = "komodo-1"
[server.config]
address = "https://10.10.10.31:8120"
region = "Singapore"
enabled = true

##

[[server]]
name = "komodo-2"
[server.config]
address = "https://10.10.10.32:8120"
region = "Singapore"
enabled = true

##

[[server]]
name = "komodo-3"
[server.config]
address = "https://10.10.10.33:8120"
region = "Singapore"
enabled = true

##

[[stack]]
name = "actual-budget"
tags = [
  "internal",
  "production",
  "komodo-2"
]
[stack.config]
server = "komodo-2"
project_name = "actual-budget"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  actual_server:
    image: docker.io/actualbudget/actual-server:latest
    ports:
      - '5006:5006'
    env_file:
      - .env  
    volumes:
      - ${DOCKER_DATA}/actualbudget:/data
    healthcheck:
      # Enable health check for the instance
      test: ['CMD-SHELL', 'node src/scripts/health-check.js']
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 20s
    restart: unless-stopped
    labels:
      proxy.aliases: actual
      proxy.actual.port: 5006
      proxy.idle_timeout: 30m
"""
environment = """
PUID=1000
PGID=1000
      # Uncomment any of the lines below to set configuration options.
      # - ACTUAL_HTTPS_KEY=/data/selfhost.key
      # - ACTUAL_HTTPS_CERT=/data/selfhost.crt
      # - ACTUAL_PORT=5006
      # - ACTUAL_UPLOAD_FILE_SYNC_SIZE_LIMIT_MB=20
      # - ACTUAL_UPLOAD_SYNC_ENCRYPTED_FILE_SYNC_SIZE_LIMIT_MB=50
      # - ACTUAL_UPLOAD_FILE_SIZE_LIMIT_MB=20
      # See all options and more details at https://actualbudget.github.io/docs/Installing/Configuration
      # !! If you are not using any of these options, remove the 'environment:' tag entirely.
"""

##

[[stack]]
name = "authentik"
tags = [
  "external",
  "production",
  "komodo-1"
]
[stack.config]
server = "komodo-1"
project_name = "authentik"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  postgresql:
    image: docker.io/library/postgres:16-alpine
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}"]
      start_period: 20s
      interval: 30s
      retries: 5
      timeout: 5s
    volumes:
      - database:/var/lib/postgresql/data
    environment:
      POSTGRES_PASSWORD: ${PG_PASS}
      POSTGRES_USER: ${PG_USER}
      POSTGRES_DB: ${PG_DB}
    env_file:
      - .env
  redis:
    image: docker.io/library/redis:alpine
    command: --save 60 1 --loglevel warning
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep PONG"]
      start_period: 20s
      interval: 30s
      retries: 5
      timeout: 3s
    volumes:
      - redis:/data
  server:
    image: ${AUTHENTIK_IMAGE:-ghcr.io/goauthentik/server}:${AUTHENTIK_TAG:-2025.6.2}
    restart: unless-stopped
    command: server
    container_name: authentik
    environment:
      AUTHENTIK_SECRET_KEY: ${AUTHENTIK_SECRET_KEY}
      AUTHENTIK_REDIS__HOST: redis
      AUTHENTIK_POSTGRESQL__HOST: postgresql
      AUTHENTIK_POSTGRESQL__USER: ${PG_USER:-authentik}
      AUTHENTIK_POSTGRESQL__NAME: ${PG_DB:-authentik}
      AUTHENTIK_POSTGRESQL__PASSWORD: ${PG_PASS}
    volumes:
      - ${DOCKER_DATA}/authentik/media:/media
      - ${DOCKER_DATA}/authentik/custom-templates:/templates
    env_file:
      - .env
    ports:
      - "${COMPOSE_PORT_HTTP:-9000}:9000"
      - "${COMPOSE_PORT_HTTPS:-9443}:9443"
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
    labels:
       proxy.aliases: auth
       proxy.auth.port: 9000
  worker:
    image: ${AUTHENTIK_IMAGE:-ghcr.io/goauthentik/server}:${AUTHENTIK_TAG:-2025.6.2}
    restart: unless-stopped
    command: worker
    environment:
      AUTHENTIK_SECRET_KEY: ${AUTHENTIK_SECRET_KEY}
      AUTHENTIK_REDIS__HOST: redis
      AUTHENTIK_POSTGRESQL__HOST: postgresql
      AUTHENTIK_POSTGRESQL__USER: ${PG_USER}
      AUTHENTIK_POSTGRESQL__NAME: ${PG_DB}
      AUTHENTIK_POSTGRESQL__PASSWORD: ${PG_PASS}
    # `user: root` and the docker socket volume are optional.
    # See more for the docker socket integration here:
    # https://goauthentik.io/docs/outposts/integrations/docker
    # Removing `user: root` also prevents the worker from fixing the permissions
    # on the mounted folders, so when removing this make sure the folders have the correct UID/GID
    # (1000:1000 by default)
    user: root
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ${AUTHENTIK_DATA_DIR}/media:/media
      - ./certs:/certs
      - ${AUTHENTIK_DATA_DIR}/custom-templates:/templates
    env_file:
      - .env
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy

volumes:
  database:
    driver: local
  redis:
    driver: local
"""
environment = """
PG_USER= authentik
PG_DB= authentik
AUTHENTIK_SECRET_KEY= [[AUTHENTIK_SECRET_KEY]]
PG_PASS= [[AUTHENTIK_PG_PASS]]
# SMTP Host Emails are sent to
AUTHENTIK_EMAIL__HOST=localhost
AUTHENTIK_EMAIL__PORT=25
# Use StartTLS
AUTHENTIK_EMAIL__USE_TLS=false
# Use SSL
AUTHENTIK_EMAIL__USE_SSL=false
AUTHENTIK_EMAIL__TIMEOUT=10
# Email address authentik will send from, should have a correct @domain
AUTHENTIK_EMAIL__FROM=authentik@localhost
COMPOSE_PORT_HTTP=9111
COMPOSE_PORT_HTTPS=9444
"""

##

[[stack]]
name = "authentik-outpost-33"
[stack.config]
server = "komodo-3"
project_name = "authentik"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
    authentik_proxy:
        image: ghcr.io/goauthentik/proxy:2025.6.2
        restart: unless-stopped
        # Optionally specify which networks the container should be
        # might be needed to reach the core authentik server
        # networks:
        #   - foo
        ports:
            - 9001:9001
            - 9444:9444
        environment:
            AUTHENTIK_HOST: https://auth.d3adc3ii.cc
            AUTHENTIK_INSECURE: "false"
            AUTHENTIK_TOKEN: 5rw0z0liBvwUBPlLeCLwULg2gZbzLPCiGItYcL8oT3JI9RH86KUl4xQkrSDX
            # Starting with 2021.9, you can optionally set this too
            # when authentik_host for internal communication doesn't match the public URL
            # AUTHENTIK_HOST_BROWSER: https://external-domain.tld
"""

##

[[stack]]
name = "beszel"
tags = [
  "komodo-1",
  "external",
  "monitoring",
  "beszel"
]
[stack.config]
server = "komodo-1"
file_contents = """
services:
  beszel:
    image: henrygd/beszel:latest
    container_name: beszel
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - 8090:8090
    volumes:
      - ${DOCKER_DATA}/beszel/beszel_data:/beszel_data
      - ${DOCKER_DATA}/beszel/beszel_socket:/beszel_socket
  beszel-agent:
    image: henrygd/beszel-agent:latest
    container_name: beszel-agent
    restart: unless-stopped
    network_mode: host
    volumes:
      - ${DOCKER_DATA}/beszel/beszel_socket:/beszel_socket
      - /var/run/docker.sock:/var/run/docker.sock:ro
    env_file:
      - .env
    environment:
      LISTEN: /beszel_socket/beszel.sock
      # Do not remove quotes around the key
      KEY: 'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIG+PtfmPHdKiaE+gbET/6wZeFSnsUEgOXpKM1qJ4gCPp'
"""
environment = """
PGID=1000
PUID=1000
"""

##

[[stack]]
name = "beszel-agent-k2"
tags = ["agent", "komodo-2", "beszel"]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  beszel-agent:
    image: "henrygd/beszel-agent"
    container_name: "beszel-agent"
    restart: unless-stopped
    network_mode: host
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # monitor other disks / partitions by mounting a folder in /extra-filesystems
      # - /mnt/disk/.beszel:/extra-filesystems/sda1:ro
    environment:
      LISTEN: 45876
      KEY: "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIG+PtfmPHdKiaE+gbET/6wZeFSnsUEgOXpKM1qJ4gCPp"
"""

##

[[stack]]
name = "beszel-agent-k3"
tags = ["komodo-3", "agent", "beszel"]
[stack.config]
server = "komodo-3"
file_contents = """
services:
  beszel-agent:
    image: "henrygd/beszel-agent"
    container_name: "beszel-agent-k3"
    restart: unless-stopped
    network_mode: host
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # monitor other disks / partitions by mounting a folder in /extra-filesystems
      # - /mnt/disk/.beszel:/extra-filesystems/sda1:ro
    environment:
      LISTEN: 45876
      KEY: "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIG+PtfmPHdKiaE+gbET/6wZeFSnsUEgOXpKM1qJ4gCPp"
"""

##

[[stack]]
name = "caddy"
tags = [
  "internal",
  "production",
  "core",
  "komodo-1"
]
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  caddy: 
    name: caddy
    ipam:
      driver: default  
    
# Main Caddy
services:
  caddy:
    image: homeall/caddy-reverse-proxy-cloudflare:latest
    networks:
      - caddy
    ports:
      - 80:80
      - 443:443
      - "443:443/udp"
    env_file:
      - .env
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ${DOCKER_DATA}/caddy/data:/data
      - ${DOCKER_DATA}/caddy/config/:/config/caddy  #ðŸ‘ˆ where to save configs 
    restart: unless-stopped
    extra_hosts:
      - host.docker.internal:host-gateway

# Caddy-config container
  caddy-config:
    container_name: caddy-config
    image: traefik/whoami:latest
    networks:
      - caddy
    restart: always
    env_file:
      - .env
    labels:
    #############################################
    # Settings and snippets to get things working
    # You shouldn't need to modify this normally
    # Custom settings and definitions are below
    #############################################

      #### Global Settings ####
      caddy_0.email: ${CADDY_EMAIL}
      caddy_0.auto_https: prefer_wildcard

      #### Snippets ####
      # Get wildcard certificate
      caddy_1: (wildcard)
      #caddy_1.acme_dns: "cloudflare ${CF_API_TOKEN}" 
      caddy_1.tls.dns: "cloudflare ${CF_API_TOKEN}"
      caddy_1.tls.resolvers: 1.1.1.1 1.0.0.1
      caddy_1.handle.abort: ""

      # Skip TLS verify for backend with self-signed HTTPS
      caddy_3: (https)
      caddy_3.transport: http
      caddy_3.transport.tls: ""
      caddy_3.transport.tls_insecure_skip_verify: ""

    ###########################################
    # Custom settings. Modify things below ðŸ‘‡:
    # Make sure they have unique label numbers
    ###########################################

      # Custom global settings, add/edit as needed
      # caddy_0.log: default
      # caddy_0.log.format: console

      # Uncomment this during testing to avoid hitting rate limit.
      # It will try to obtain SSL from Let's Encrypt's staging endpoint.
      # acme_ca: "https://acme-staging-v02.api.letsencrypt.org/directory" # ðŸ‘ˆ Staging

      ## Setup wildcard sites
      caddy_10: "*.d3adc3ii.site"   #ðŸ‘ˆ Change to your domain
      caddy_10.import: wildcard

      # Caddy Admin Endpoint and Metrics
      caddy_20: :2020
      #caddy_20.admin: "0.0.0.0:2019"
      #caddy_20.admin.origin: "caddy.d3adc3ii.site"
      caddy_20.handle: /reverse_proxy/upstreams
      caddy_20.handle.reverse_proxy: localhost:2019
      caddy_20.handle.reverse_proxy.header_up: Host localhost:2019
    

      # Add our first site, which this container itself
      caddy_99: whoami.d3adc3ii.site                       #ðŸ‘ˆ Subdomain using wildcard cert
      caddy_99.reverse_proxy: "{{upstreams 80}}"         #ðŸ‘ˆ Container port

      # For non-docker sites see https://gist.github.com/omltcat/241ef622070ca0580f2876a7cfa7de67
      # e.g.: Pi-Hole on another machine in the same LAN
      caddy_100: netalertx.d3adc3ii.site                      
      caddy_100.reverse_proxy: 192.168.2.31:20184

      caddy_101: pve.d3adc3ii.site                      
      caddy_101.reverse_proxy: 192.168.2.11:8006
      caddy_101.reverse_proxy.transport: http
      caddy_101.reverse_proxy.transport.tls_insecure_skip_verify: ""


      caddy_102: opn.d3adc3ii.site                      
      caddy_102.reverse_proxy: 192.168.2.1:2184
      caddy_102.reverse_proxy.transport: http
      caddy_102.reverse_proxy.transport.tls: ""
      caddy_102.reverse_proxy.transport.versions: 1.1 1.2
      caddy_102.reverse_proxy.transport.tls_insecure_skip_verify: ""

      caddy_103: truenas.d3adc3ii.site                      
      caddy_103.reverse_proxy: 192.168.2.7
      caddy_103.reverse_proxy.transport: http
      caddy_103.reverse_proxy.transport.tls_insecure_skip_verify: ""

      caddy_104: pbs.d3adc3ii.site   
      caddy_104.reverse_proxy: 192.168.2.35:8007
      caddy_104.reverse_proxy.transport: http
      caddy_104.reverse_proxy.transport.tls_insecure_skip_verify: ""

      caddy_105: ns0.d3adc3ii.site                      
      caddy_105.reverse_proxy: 192.168.2.5:5380
      caddy_106: stash.d3adc3ii.site                      
      caddy_106.reverse_proxy: 192.168.2.26:9999
      caddy_107: ha.d3adc3ii.site                      
      caddy_107.reverse_proxy: 192.168.99.5:8123    
      #caddy_108: jelly.d3adc3ii.site                      
      #caddy_108.reverse_proxy: 192.168.2.33:8096
      caddy_109: semaphore.d3adc3ii.site                      
      caddy_109.reverse_proxy: 192.168.2.28:3000            
      caddy_110: aria.d3adc3ii.site                      
      caddy_110.reverse_proxy: 192.168.2.16:6880  
      caddy_111: pulse.d3adc3ii.site                      
      caddy_111.reverse_proxy: 192.168.2.36:7655     
      caddy_112: backrest.d3adc3ii.site                      
      caddy_112.reverse_proxy: 192.168.2.35:9898
      caddy_113: actual.d3adc3ii.site                      
      caddy_113.reverse_proxy: 192.168.2.32:5006
      # wazuh
      caddy_114: wazuh.d3adc3ii.site                      
      caddy_114.reverse_proxy: 192.168.2.30:443
      caddy_114.reverse_proxy.transport: http
      caddy_114.reverse_proxy.transport.tls_insecure_skip_verify: ""
      # guaca
      caddy_115: guaca.d3adc3ii.site                      
      caddy_115.reverse_proxy: 192.168.2.20
      #caddy_116: checkmate.d3adc3ii.site                      
      #caddy_116.reverse_proxy: 192.168.2.33:52345  
      #caddy_117: checkmate2.d3adc3ii.site                      
      #caddy_117.reverse_proxy: 192.168.2.32:59232
      #caddy_118: checkmate3.d3adc3ii.site                      
      #caddy_118.reverse_proxy: 192.168.2.33:59232    

      # e.g. OpenMediaVault on the host machine, with self-signed https at port 4430
      #caddy_101: omv.example.com                         #ðŸ‘ˆ Subdomain using wildcard cert
      #caddy_101.reverse_proxy: host.docker.internal:4430 #ðŸ‘ˆ Port on host machine
      #caddy_101.reverse_proxy.import: https              #ðŸ‘ˆ Allow self-signed cert between OMV and Caddy
      #caddy_101.import: auth                             #ðŸ‘ˆ Enable protection by Authelia
"""
environment = """
PUID= [[PUID]]
PGID= [[PGID]]
CADDY_INGRESS_NETWORKS=caddy
CF_API_TOKEN= [[CF_API_TOKEN]]
CADDY_EMAIL= d3tech@pm.me
"""

##

[[stack]]
name = "discord-alerter"
[stack.config]
server = "komodo-2"
repo = "foxxmd/deploy-discord-alerter"
file_paths = ["compose.yaml"]
environment = """
  ## Required

  ## Your webhook URL
  DISCORD_WEBHOOK = [[DISCORD_WEBHOOK]]

  ## Optional

  ## Set whether to include Komodo Severity Level in notification title
  #LEVEL_IN_TITLE=true

  # Prefixes messages with a checkmark when the Alert is in the 'Resolved' state
  #INDICATE_RESOLVED=true

  # Filter if an alert is pushed based on its Resolved status
  # * leave unset to push all alerts
  # * otherwise, alerts will only be pushed if Alert is one of the comma-separated states set here
  #ALLOW_RESOLVED_TYPE=resolved,unresolved

  ## Delay alerts with below types for X milliseconds 
  ## and cancel pushing alert if it is resolved within that time
  #UNRESOLVED_TIMEOUT_TYPES=ServerCpu,ServerMem
  #UNRESOLVED_TIMEOUT=2000
"""

##

[[stack]]
name = "doxy-33"
[stack.config]
server = "komodo-3"
file_contents = """
services:
  agent:
    image: "ghcr.io/yusing/godoxy-agent:nightly"
    container_name: godoxy-agent
    restart: always
    network_mode: host # do not change this
    environment:
      AGENT_NAME: "doxy-33"
      AGENT_PORT: "8890"
      AGENT_CA_CERT: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJsVENDQVR1Z0F3SUJBZ0lRVXhyZlZJdGtXMFpGUkZTeEkwcWpuekFLQmdncWhrak9QUVFEQWpBb01ROHcKRFFZRFZRUUtFd1pIYjBSdmVIa3hGVEFUQmdOVkJBTVRER2R2Wkc5NGVTNWhaMlZ1ZERBZ0Z3MHlOVEEyTWpReQpNVE13TXpWYUdBOHpNREkxTURZeU5ESXhNekF6TlZvd0tERVBNQTBHQTFVRUNoTUdSMjlFYjNoNU1SVXdFd1lEClZRUURFd3huYjJSdmVIa3VZV2RsYm5Rd1dUQVRCZ2NxaGtqT1BRSUJCZ2dxaGtqT1BRTUJCd05DQUFSeGVmN0gKWFMwbXJpeFFTRVJ4b3VocWRCamozZEM0K3dOcHhIZnB5ck9qeHlYMHBGNWh6L3N3V3IvZnlpaDdiSkdDV1VRKwpXYnFRdWc3U1pNYkFmZEZSbzBVd1F6QU9CZ05WSFE4QkFmOEVCQU1DQVFZd0VnWURWUjBUQVFIL0JBZ3dCZ0VCCi93SUJBREFkQmdOVkhRNEVGZ1FVcjF6UitmNG9RS28zci9seCtyNXl6aUxxMjdBd0NnWUlLb1pJemowRUF3SUQKU0FBd1JRSWdEOTZRU3ZVUmRSTDFTS3pnUVVaVVluWGxjQVY1OVdaSHZoeFNQRE9HK0ZjQ0lRQ3NsZ0xkeHNGTQpjWXdPSjM0Q1lESlBkWnFRS1QzQWlBNFhweXJsS1FPdWdnPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=;LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUV3ZHcxOEV5T21OUXhvd2pOV2poSnNsdjNEZ0NpekRweDZ0SDJqZ3J4dW5vQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFY1huK3gxMHRKcTRzVUVoRWNhTG9hblFZNDkzUXVQc0RhY1IzNmNxem84Y2w5S1JlWWMvNwpNRnEvMzhvb2UyeVJnbGxFUGxtNmtMb08wbVRHd0gzUlVRPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo="
      AGENT_SSL_CERT: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJvakNDQVVlZ0F3SUJBZ0lRWFJ5S1pJanpkd2tsQlFzbWpmU29oakFLQmdncWhrak9QUVFEQWpBb01ROHcKRFFZRFZRUUtFd1pIYjBSdmVIa3hGVEFUQmdOVkJBTVRER2R2Wkc5NGVTNWhaMlZ1ZERBZ0Z3MHlOVEEyTWpReQpNVE13TXpWYUdBOHpNREkxTURZeU5ESXhNekF6TlZvd09URVBNQTBHQTFVRUNoTUdSMjlFYjNoNU1ROHdEUVlEClZRUUxFd1pUWlhKMlpYSXhGVEFUQmdOVkJBTVRER2R2Wkc5NGVTNWhaMlZ1ZERCWk1CTUdCeXFHU000OUFnRUcKQ0NxR1NNNDlBd0VIQTBJQUJCR2NjcnVpNk4wcitWQW5QRGJTQ2F4WmR6clNYMVdjSjNobFBsM3Y3cjlXbkxueAp1c0YvY1hiMGlNaGtmeURYOXd3NjhndllyMVg3MUhEb0hnYzBmU2FqUURBK01BNEdBMVVkRHdFQi93UUVBd0lICmdEQVRCZ05WSFNVRUREQUtCZ2dyQmdFRkJRY0RBVEFYQmdOVkhSRUVFREFPZ2d4bmIyUnZlSGt1WVdkbGJuUXcKQ2dZSUtvWkl6ajBFQXdJRFNRQXdSZ0loQU1mVG45aXdvOTA0OWZramxNY01sblFyQklmSUJjQm9Id0FiamYxZgpqVUhoQWlFQTd2emRVY2dUNkQzSklzajBkYUFadlNXUld4T040Q21OZE5NMWgxaU9RcDA9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K;LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUdZdHZQQXZOcWY4Q2RIcGRJVTBDeTVFVVlpRmJXN3hlMHlzdklRZ1c5WHRvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFRVp4eXU2TG8zU3Y1VUNjOE50SUpyRmwzT3RKZlZad25lR1UrWGUvdXYxYWN1Zkc2d1g5eApkdlNJeUdSL0lOZjNERHJ5QzlpdlZmdlVjT2dlQnpSOUpnPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo="
      # use agent as a docker socket proxy: [host]:port
      # set LISTEN_ADDR to enable (e.g. 127.0.0.1:2375)
      LISTEN_ADDR:
      POST: false
      ALLOW_RESTARTS: false
      ALLOW_START: false
      ALLOW_STOP: false
      AUTH: false
      BUILD: false
      COMMIT: false
      CONFIGS: false
      CONTAINERS: false
      DISTRIBUTION: false
      EVENTS: true
      EXEC: false
      GRPC: false
      IMAGES: false
      INFO: false
      NETWORKS: false
      NODES: false
      PING: true
      PLUGINS: false
      SECRETS: false
      SERVICES: false
      SESSION: false
      SWARM: false
      SYSTEM: false
      TASKS: false
      VERSION: true
      VOLUMES: false
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data:/app/data
"""

##

[[stack]]
name = "dozzel-agent-1"
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  dozzle-agent:
    image: amir20/dozzle:latest
    command: agent
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    ports:
      - 7007:7007
"""

##

[[stack]]
name = "dozzle"
tags = [
  "internal",
  "monitoring",
  "komodo-3",
  "docker"
]
[stack.config]
server = "komodo-3"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  dozzle:
    image: amir20/dozzle:latest
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 8787:8080
    env_file:
      - .env
    labels:
      proxy.dozzle.port: 8787
      proxy.dozzle-backend.port: 8080
"""
environment = """
DOZZLE_ENABLE_ACTIONS=true
DOZZLE_ENABLE_SHELL=true
#DOZZLE_AUTH_PROVIDER: forward-proxy
DOZZLE_REMOTE_AGENT=10.10.10.31:7007,10.10.10.32:7007
"""

##

[[stack]]
name = "dozzle-agent-2"
tags = [
  "internal",
  "monitoring",
  "komodo-2"
]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  dozzle-agent:
    image: amir20/dozzle:latest
    command: agent
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    ports:
      - 7007:7007
"""

##

[[stack]]
name = "dumbterm"
tags = [
  "external",
  "production",
  "komodo-2"
]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  dumbterm:
    image: dumbwareio/dumbterm:latest
    container_name: dumbterm
    restart: unless-stopped
    ports:
      - ${DUMBTERM_PORT}:3000
    volumes:
      - ${DUMBTERM_CONFIG}:/root/.config
      - ${DUMBTERM_DATA_DIR}:/root/data
    environment:
      # Container timezone
      TZ: ${DUMBTERM_TZ}
      # The title shown in the web interface
      SITE_TITLE: ${DUMBTERM_SITE_TITLE:-DumbTerm}
      # Recommended PIN protection (leave empty to disable)
      DUMBTERM_PIN: ${DUMBTERM_PIN}
      # The base URL for the application
      BASE_URL: ${DUMBTERM_BASE_URL}
      ENABLE_STARSHIP: ${ENABLE_STARSHIP:-true}
      LOCKOUT_TIME: ${DUMBTERM_LOCKOUT_TIME:-15} # Minutes
      # Session duration in hours before requiring re-authentication
      MAX_SESSION_AGE: ${DUMBTERM_MAX_SESSION_AGE:-24} # Hours
      # (OPTIONAL) - List of allowed origins for CORS
      # ALLOWED_ORIGINS: ${DUMBTERM_ALLOWED_ORIGINS:-http://localhost:3000}
    labels:
      proxy.idle_timeout: 30m
"""
environment = """
DUMBTERM_CONFIG="/mnt/zApps/dumbterm/config"
DUMBTERM_DATA_DIR="/mnt/zApps/dumbterm/data"
DUMBTERM_TZ="Asia/Singapore"
DUMBTERM_PIN=1111
DUMBTERM_PORT=3002
DUMBTERM_BASE_URL=http://dumbterm.d3adc3ii.cc:3002
"""

##

[[stack]]
name = "godoxy"
tags = [
  "internal",
  "core",
  "proxy",
  "komodo-3"
]
[stack.config]
server = "komodo-1"
project_name = "godoxy"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
---
services:
  socket-proxy:
    container_name: socket-proxy
    image: ghcr.io/yusing/socket-proxy:latest
    environment:
      - ALLOW_START=1
      - ALLOW_STOP=1
      - ALLOW_RESTARTS=1
      - CONTAINERS=1
      - EVENTS=1
      - INFO=1
      - PING=1
      - POST=1
      - VERSION=1
    volumes:
      - ${DOCKER_SOCKET:-/var/run/docker.sock}:/var/run/docker.sock
    restart: unless-stopped
    tmpfs:
      - /run
    ports:
      - ${SOCKET_PROXY_LISTEN_ADDR:-127.0.0.1:2375}:2375
  frontend:
    image: ghcr.io/yusing/godoxy-frontend:${TAG:-latest}
    container_name: godoxy-frontend
    restart: unless-stopped
    network_mode: host
    env_file: .env
    user: 1000:1000
    read_only: true
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - all
    depends_on:
      - app
    environment:
      HOSTNAME: 127.0.0.1
      PORT: ${GODOXY_FRONTEND_PORT}
    labels:
      proxy.aliases: ${GODOXY_FRONTEND_ALIASES}
      proxy.doxy.port: ${GODOXY_FRONTEND_PORT}
     # proxy.doxy.middlewares.oidc:
      # proxy.#1.middlewares.cidr_whitelist: |
      #   status: 403
      #   message: IP not allowed
      #   allow:
      #     - 127.0.0.1
      #     - 10.0.0.0/8
      #     - 192.168.0.0/16
      #     - 172.16.0.0/12
  app:
    image: ghcr.io/yusing/godoxy:${TAG:-latest}
    container_name: godoxy-proxy
    restart: always
    network_mode: host # do not change this
    #extra_hosts:
    #  - auth.d3adc3ii.cc:127.0.0.1
    dns:
      - 1.1.1.1
      - 1.1.1.2
    environment:
      - CF_API_TOKEN= ${CF_API_TOKEN}
      - CF_EMAIL= ${CF_EMAIL}
      - DOCKER_HOST=tcp://${SOCKET_PROXY_LISTEN_ADDR:-127.0.0.1:2375}
    env_file: .env
    user: 1000:1000
    depends_on:
      socket-proxy:
        condition: service_started
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - all
    cap_add:
      - NET_BIND_SERVICE
    volumes:
      - ${DOCKER_DATA}/godoxy/config:/app/config
      - ${DOCKER_DATA}/godoxy/logs:/app/logs
      - ${DOCKER_DATA}/godoxy/error_pages:/app/error_pages:ro
      - ${DOCKER_DATA}/godoxy/data:/app/data
      - ${DOCKER_DATA}/godoxy/certs:/app/certs

      # remove "./certs:/app/certs" and uncomment below to use existing certificate
      # - /path/to/certs/cert.crt:/app/certs/cert.crt
      # - /path/to/certs/priv.key:/app/certs/priv.key
"""
environment = """
COMPOSE_PROJECT_NAME= godoxy
TAG=latest
TZ=Asia/Singapore
PUID=1000
PGID=1000
GODOXY_EMAIL= d3tech@pm.me
CONFIG_DIR=/etc/komodo/repos/diiihl-3/komodo/resources/godoxy/config
CF_API_TOKEN= [[CF_API_TOKEN]]
CF_EMAIL= d3tech@pm.me
# API JWT Configuration (common)
# generate secret with `openssl rand -base64 32`
GODOXY_API_JWT_SECRET=4m64Gth6C6VZeLHxGOQzVe3Myigx5gqHm4KqN5HxwM8=
# the JWT token time-to-live
# leave empty to use default (24 hours)
# format: https://pkg.go.dev/time#Duration
GODOXY_API_JWT_TOKEN_TTL=

# API/WebUI user password login credentials (optional)
# These fields are not required for OIDC authentication
GODOXY_API_USER=d3
GODOXY_API_PASSWORD=qyp.kmr2ktf5vcj3CYM

# OIDC Configuration (optional)
# Uncomment and configure these values to enable OIDC authentication.
#

#GODOXY_OIDC_ISSUER_URL= https://auth.d3adc3ii.cc/application/o/godoxy/                       
#GODOXY_OIDC_CLIENT_ID=LLYuk9x6gWycwkdfiAsjVQtANvtuQyqH4iVHQmMK
#GODOXY_OIDC_CLIENT_SECRET=FKnuEPQQRq5ZTu2hBhd2uTeCjWg1CT6PtjgD1d2AcBZK2L0BYomunCWhkO7vcuNdAHfD0MbZEeqiFGBTAfjjWyU3FRdgLyqh3bsoGTM7zCf7O7wdPrZW4SIQeLRLfqCm
#GODOXY_OIDC_SCOPES=openid, profile, email, groups
#GODOXY_OIDC_ALLOWED_USERS=d3
# User definitions: Uncomment and configure these values to restrict access to specific users or groups.
# These two fields act as a logical AND operator. For example, given the following membership:
#   user1, group1
#   user2, group1
#   user3, group2
#   user1, group2
# You can allow access to user3 AND all users of group1 by providing:
#   # GODOXY_OIDC_ALLOWED_USERS=user3
#GODOXY_OIDC_ALLOWED_GROUPS=	"authentik Admins"
#
# Comma-separated list of allowed users.
# GODOXY_OIDC_ALLOWED_USERS=user1,user2
# Optional: Comma-separated list of allowed groups.
# GODOXY_OIDC_ALLOWED_GROUPS=group1,group2

# Proxy listening address
GODOXY_HTTP_ADDR=:80
GODOXY_HTTPS_ADDR=:443

# Enable HTTP3
GODOXY_HTTP3_ENABLED=true

# API listening address
GODOXY_API_ADDR=127.0.0.1:8888

# Metrics
GODOXY_METRICS_DISABLE_CPU=false
GODOXY_METRICS_DISABLE_MEMORY=false
GODOXY_METRICS_DISABLE_DISK=false
GODOXY_METRICS_DISABLE_NETWORK=false
GODOXY_METRICS_DISABLE_SENSORS=false

# Frontend listening port
GODOXY_FRONTEND_PORT=3716

# Frontend aliases (subdomains / FQDNs, e.g. godoxy, godoxy.domain.com)
GODOXY_FRONTEND_ALIASES=doxy

# Docker socket
# /var/run/podman/podman.sock for podman
DOCKER_SOCKET=/var/run/docker.sock
SOCKET_PROXY_LISTEN_ADDR=127.0.0.1:2375

# Debug mode
GODOXY_DEBUG=true
"""

##

[[stack]]
name = "healthcheck"
tags = [
  "internal",
  "monitoring",
  "komodo-1"
]
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
#networks:
#  caddy:
#    external: true

services:
  healthchecks:
    image: lscr.io/linuxserver/healthchecks:latest
    container_name: healthchecks
    #networks:
    #  - caddy
    env_file:
      - .env
    #environment:
      #- CSRF_TRUSTED_ORIGINS= #optional
      #- DEBUG=True #optional
      #- DEFAULT_FROM_EMAIL= #optional
      #- EMAIL_HOST= #optional
      #- EMAIL_PORT= #optional
      #- EMAIL_HOST_USER= #optional
      #- EMAIL_HOST_PASSWORD= #optional
      #- EMAIL_USE_TLS= #optional
      #- INTEGRATIONS_ALLOW_PRIVATE_IPS= #optional
      #- PING_EMAIL_DOMAIN= #optional
      #- RP_ID= #optional
      #- SITE_LOGO_URL= #optional
    volumes:
      - ${DATA_DIR}/config:/config
    ports:
      - 8898:8000
      - 2525:2525 #optional
    restart: unless-stopped
    labels:
       proxy.idle_timeout: 1h
       proxy.port: 8898
"""
environment = """
PUID=1000
PGID=1000
DATA_DIR=/mnt/zApps/healthcheck
SITE_ROOT= "https://health.d3adc3ii.site"
ALLOWED_HOSTS=health.d3adc3ii.site
SITE_NAME= Healthcheck
SUPERUSER_EMAIL= d3tech@pm.me
SUPERUSER_PASSWORD= [[HEALTHCHECK_SUPERADMIN_PASSWORD]]
SECRET_KEY= [[HEALTHCHECK_SECRET]]
APPRISE_ENABLED=True
TZ=Asia/Singapore
"""

##

[[stack]]
name = "homepage"
tags = [
  "external",
  "production",
  "komodo-1"
]
[stack.config]
server = "komodo-1"
links = ["https://homepage.d3adc3ii.cc"]
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
#networks:
#  caddy:
#    external: true

services:
  homepage:
    image: ghcr.io/gethomepage/homepage:dev
    container_name: homepage
#    networks:
#      - caddy
    env_file:
      - .env
    ports:
      - 3731:3000
    volumes:
      - ${HOMEPAGE_DATA_DIR}/homepage/config:/app/config 
      - ${HOMEPAGE_DATA_DIR}/homepage/icons:/app/public/icons
      - ${HOMEPAGE_DATA_DIR}/homepage/images:/app/public/images 
      - /var/run/docker.sock:/var/run/docker.sock:ro
    restart: unless-stopped
"""
environment = """
HOMEPAGE_DATA_DIR= /etc/komodo/repos/diiihl/komodo/resources/
HOMEPAGE_ALLOWED_HOSTS= "homepage.d3adc3ii.cc,homepage.d3adc3ii.site,10.10.10.31:3000"
PGID= [[PGID]] 
PUID= [[PUID]] 
# Site Config
HOMEPAGE_VAR_TITLE= "d3 Homepage"
HOMEPAGE_VAR_FAVICON= "/icons/d3logo.png"
HOMEPAGE_VAR_IMG_URL= "/images/extra-12.jpg"
HOMEPAGE_VAR_HEADER_STYLE= boxed #boxedWidgets

HOMEPAGE_VAR_IMG_BLUR= md
HOMEPAGE_VAR_IMG_SATURATE= 50
HOMEPAGE_VAR_IMG_BRIGHTNESS= 50
HOMEPAGE_VAR_IMG_OPACITY=70
HOMEPAGE_VAR_THEME= dark
HOMEPAGE_VAR_COLOR= zinc
HOMEPAGE_VAR_STATUS_STYLE= dot
HOMEPAGE_VAR_IMG_FULLWIDTH= true
HOMEPAGE_VAR_IMG_SHOWSTATS= true
HOMEPAGE_VAR_IMG_HIDEERRORS= true
HOMEPAGE_VAR_USE_EQUAL_HEIGHTS= true
HOMEAGE_VAR_DISABLE_COLLAPSE= true


### GLANCES WIDGET SETTINGS
HOMEPAGE_VAR_GL11_URL= http://10.10.10.11:61208
HOMEPAGE_VAR_GL11_VERSION= 4 # required only if running glances v4 or higher, defaults to 3
HOMEPAGE_VAR_GL11_CPU= false # optional, enabled by default, disable by setting to false
HOMEPAGE_VAR_GL11_MEM= false # optional, enabled by default, disable by setting to false
HOMEPAGE_VAR_GL11_CPUTEMP= true # disabled by default
HOMEPAGE_VAR_GL11_UPTIME= true # disabled by default
HOMEPAGE_VAR_GL11_LABEL= pve11 # optional

HOMEPAGE_VAR_GL12_URL= http://10.10.10.12:61208
HOMEPAGE_VAR_GL12_VERSION= 4 
HOMEPAGE_VAR_GL12_CPU= false 
HOMEPAGE_VAR_GL12_MEM= false 
HOMEPAGE_VAR_GL12_CPUTEMP= true 
HOMEPAGE_VAR_GL12_UPTIME= true 
HOMEPAGE_VAR_GL12_LABEL= pve12 

HOMEPAGE_VAR_GL13_URL= http://10.10.10.13:61208
HOMEPAGE_VAR_GL13_VERSION= 4
HOMEPAGE_VAR_GL13_CPU= false 
HOMEPAGE_VAR_GL13_MEM= false 
HOMEPAGE_VAR_GL13_CPUTEMP= true 
HOMEPAGE_VAR_GL13_UPTIME= true 
HOMEPAGE_VAR_GL13_LABEL= pve13 

### INFRA ###
# PULSE
HOMEPAGE_VAR_PULSE_URL= "http://10.10.10.36:7655"
HOMEPAGE_VAR_PULSE_ALLOWFULLSCREEN= true
HOMEPAGE_VAR_PULSE_LOADING_STRATEGY=eager
HOMEPAGE_VAR_PULSE_ALLOW_SCROLLING=false
HOMEPAGE_VAR_PULSE_CLASSES= h-60 sm:h-60 md:h-100 lg:h-200 xl:h-300 2xl:h-700
#HOMEPAGE_VAR_PULSE_HEIGHT= 500

# Truenas
HOMEPAGE_VAR_TRUENAS_ICON= "/icons/truenas-scale-light.png"
HOMEPAGE_VAR_TRUENAS_URL= "https://truenas.d3adc3ii.site"
HOMEPAGE_VAR_TRUENAS_KEY="1-zM5Mm8l4VdRa4WNybTWjVdHVM89TR7fkGj40DkYEPgFdkt83DYBea95J3SHe3uCe"
HOMEPAGE_VAR_TRUENAS_ENABLEDPOOL= true
# Proxmox
HOMEPAGE_VAR_PROXMOX_ICON= "/icons/proxmox-light.png"
HOMEPAGE_VAR_PROXMOX_URL_PVE_1= "https://pve.d3adc3ii.site"
#HOMEPAGE_VAR_PROXMOX_USER= 
#HOMEPAGE_VAR_PROXMOX_API_KEY=
HOMEPAGE_VAR_PBS_URL= "https://pbs.d3adc3ii.site"

### INFRA ###
# Opnsense
HOMEPAGE_VAR_OPNSENSE_ICON= "/icons/opnsense-light.png"
HOMEPAGE_VAR_OPNSENSE_URL= "https://opn.d3adc3ii.site"
# DNS
HOMEPAGE_VAR_DNS_ICON= "/icons/technitium-light.png"
HOMEPAGE_VAR_DNS_URL= "https://ns0.d3adc3ii.site"
HOMEPAGE_VAR_DNS_KEY="664be7cf433c98c60e66d81cc782a9226cc8ba2e255933727285174f62980b1c"
HOMEPAGE_VAR_DNS_RANGE: LastDay # optional, defaults to LastHour
# MIKROTIK
HOMEPAGE_VAR_MIKROTIK_ICON= "/icons/mikrotik-light.png"
HOMEPAGE_VAR_MIKROTIK_URL= "http://mik253.d3adc3ii.site"
# TPLINK
HOMEPAGE_VAR_TPLINK_ICON= "/icons/tp-link-light.png"
HOMEPAGE_VAR_TPLINK_URL= "http://tpl252.d3adc3ii.cite"

### Monitoring ###
# SPEEDTEST
HOMEPAGE_VAR_SPEEDTEST_ICON= "sh-speedtest-tracker-light"
HOMEPAGE_VAR_SPEEDTEST_URL= "https://speedtest.d3adc3ii.site"
# GoDoxy
HOMEPAGE_VAR_GODOXY_ICON= "/icons/godoxy-light.png"
HOMEPAGE_VAR_GODOXY_URL= "https://doxy.d3adc3ii.site"
# Dozzle
HOMEPAGE_VAR_DOZZLE_ICON= "sh-dozzle-light"
HOMEPAGE_VAR_DOZZLE_URL= "https://dozzle.d3adc3ii.site"
# Caddy Proxy
HOMEPAGE_VAR_CADDYPROXY_ICON= "/icons/caddy-light.png"
HOMEPAGE_VAR_CADDYPROXY_URL= "http://caddy:2020"
# NetAlertX 
HOMEPAGE_VAR_NETALERTX_ICON= "/icons/netalertx-light.png"
HOMEPAGE_VAR_NETALERTX_URL= "https://netalertx.d3adc3ii.site"
HOMEPAGE_VAR_NETALERTX_KEY="t_pJ26L2qEeUcR6bz5RCGI"
HOMEPAGE_VAR_NETALERTX_FIELDS= ["connected","down_alerts","new_devices"] 
# Wazuh
HOMEPAGE_VAR_WAZUH_ICON= "/icons/wazuh-light.png"
HOMEPAGE_VAR_WAZUH_URL= "https://wazuh.d3adc3ii.site"
# APPRISE-API
HOMEPAGE_VAR_APPRISE_ICON= "/icons/gotify-dark.png"
HOMEPAGE_VAR_APPRISE_URL= "http://192.168.2.33:8000"
# Healthchecks
HOMEPAGE_VAR_HEALTHCHECKS_ICON= "/icons/healthchecks-light.png"
HOMEPAGE_VAR_HEALTHCHECKS_URL= "http://health.d3adc3ii.site"
# Smokeping
HOMEPAGE_VAR_SMOKEPING_ICON= "/icons/smokeping.png"
HOMEPAGE_VAR_SMOKEPING_URL= "http://192.168.2.21/smokeping"

### BACKUP ###
# Backrest
HOMEPAGE_VAR_BACKREST_ICON= "/icons/backrest-light.png"
HOMEPAGE_VAR_BACKREST_URL= "https://backrest.d3adc3ii.site"

# Remote-Backups
HOMEPAGE_VAR_REMOTEBACKUP_ICON= "/icons/proxmox-light.png"
HOMEPAGE_VAR_REMOTEBACKUP_URL= "https://dashboard.remote-backups.com"


# Jellyfin
HOMEPAGE_VAR_JELLY_ICON= "/icons/jellyfin-light.png"
HOMEPAGE_VAR_JELLY_URL= "https://jelly.d3adc3ii.site"
HOMEAGE_VAR_JELLY_WIDGETURL= "http://192.168.2.33:8096"
HOMEPAGE_VAR_JELLY_KEY= "a6a45c61dd1d4f059b02fa22ad8c0ef3"
HOMEPAGE_VAR_JELLY_ENABLEBLOCK=true
HOMEPAGE_VAR_JELLY_NOWPLAY=false

# Immich
HOMEPAGE_VAR_IMMICH_ICON = "/icons/immich-light.png"
HOMEPAGE_VAR_IMMICH_URL= "https://immich.d3adc3ii.site"
HOMEPAGE_VAR_IMMICH_KEY= "7zmatjhj9RVRPylp08hKaG1mkYDubUyeqfDlpaUHo"
HOMEPAGE_VAR_IMMICH_VERSION= 2
HOMEPAGE_VAR_IMMICH_FIELDS= ["storage","photos","videos"] 

### LOCAL APPS ###
# Actual Budget
HOMEPAGE_VAR_ACTUAL_ICON= "sh-actual-budget-light"
HOMEPAGE_VAR_ACTUAL_URL= "https://actual.d3adc3ii.site"
# Sensei
HOMEPAGE_VAR_SENSEI_ICON= "sh-sentry-light"
HOMEPAGE_VAR_SENSEI_URL= "https://statement.d3adc3ii.site"
# Homeassistant
HOMEPAGE_VAR_HA_ICON= "/icons/home-assistant-light.png"
HOMEPAGE_VAR_HA_URL= "https://ha.d3adc3ii.site"
# Qbit
HOMEPAGE_VAR_QBIT_ICON= "/icons/qbittorrent-light.png"
HOMEPAGE_VAR_QBIT_URL= "https://qbit.d3adc3ii.site"
HOMEPAGE_VAR_QBIT_USER= "d3adc3ii"
HOMEPAGE_VAR_QBIT_PASSWORD= "WCxb2CcykoUmjiNAf3p8"
# Stash
HOMEPAGE_VAR_STASH_ICON= "/icons/stash-light.png"
HOMEPAGE_VAR_STASH_URL= "https://stash.d3adc3ii.site"
HOMEPAGE_VAR_STASH_USER= "d3adc3ii"
HOMEPAGE_VAR_QBIT_API= "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1aWQiOiJkMyIsInN1YiI6IkFQSUtleSIsImlhdCI6MTc0NjAzOTExOX0.OQqokQMNgdCRNxfPOQGOTFH4GCB0pQvZbIS9orkgkrg"
# Semaphore
HOMEPAGE_VAR_SEMAPHORE_ICON= "/icons/semaphore-ui-light.png"
HOMEPAGE_VAR_SEMAPHORE_URL= "https://semaphore.d3adc3ii.site"
# Aria2
HOMEPAGE_VAR_ARIA_ICON= "sh-aria2-light"
HOMEPAGE_VAR_ARIA_URL= "https://dl.d3adc3ii.site"
# NZBGET
HOMEPAGE_VAR_NZBGET_ICON= "sh-nzbget-light"
HOMEPAGE_VAR_NZBGET_URL= "https://nzbget.d3adc3ii.site"








############  EXTERNAL ############ 
###################################             
###################################
###################################









# Pangolin
HOMEPAGE_VAR_PANGOLIN_ICON= "/icons/pangolin-light.png"
HOMEPAGE_VAR_PANGOLIN_URL= "https://pangolin.d3adc3ii.cc"
# Authentik
HOMEPAGE_VAR_AUTHENTIK_ICON= "/icons/authentik-light.png"
HOMEPAGE_VAR_AUTHENTIK_URL= "https://auth.d3adc3ii.cc"
HOMEPAGE_VAR_AUTHENTIK_KEY="Boy9GZM04gnN8zn1RdTDSxgkeDr70a8XqFKmrp1HwVx7A3u4GA2pnVN2aZEO"
# Komodo
HOMEPAGE_VAR_KOMODO_ICON= "/icons/docker-light.png"
HOMEPAGE_VAR_KOMODO_URL= "https://komodo.d3adc3ii.cc"
HOMEPAGE_VAR_KOMODO_APIURL= "http://192.168.2.31:9120/read"
HOMEPAGE_VAR_KOMODO_CONTAINER_UPDATE_URL= "http://container-updates-summary:5070/"
HOMEPAGE_VAR_KOMODO_API_KEY="K-zJzjausI0s5PFi0B5tpRiZzz7JEjVddtR2cPyHsX"
HOMEPAGE_VAR_KOMODO_API_SECRET="S-oOAnX7RSJ4vE7la3Tj66pPuiBODTKfXjl14jdMXW"
# Twingate
HOMEPAGE_VAR_TWINGATE_ICON= "/icons/twingate.png"
HOMEPAGE_VAR_TWINGATE_URL= "https://d3net.twinget.com"

### Remote ###
# Guacamole
HOMEPAGE_VAR_GUACAMOLE_ICON= "/icons/apache-guacamole-light.png"
HOMEPAGE_VAR_GUACAMOLE_URL= "https://guaca.d3adc3ii.site/guacamole"
HOMEPAGE_VAR_GUACAMOLEEXT_URL= "https://guaca.d3adc3ii.cc/guacamole"
# Dumbterm
HOMEPAGE_VAR_DUMBTERM_ICON= "/icons/dumbterm-light.png"
HOMEPAGE_VAR_DUMBTERM_URL= "https://dumbterm.d3adc3ii.cc"

# SHELLHUB
HOMEPAGE_VAR_SHELLHUB_ICON= "sh-shellhub-light"
HOMEPAGE_VAR_SHELLHUB_URL= "http://192.168.2.33"

# Termix
HOMEPAGE_VAR_TERMIX_ICON= "sh-termix-light"
HOMEPAGE_VAR_TERMIX_URL= "https://termix.d3adc3ii.cc"

### Monitoring ###
# UPTIME KUMA
HOMEPAGE_VAR_KUMA_ICON= "/icons/uptime-kuma-light.png"
HOMEPAGE_VAR_KUMA_URL= "https://uptime.d3adc3ii.cc"
# Grafana
HOMEPAGE_VAR_GRAFANA_ICON= "/icons/grafana-light.png"
HOMEPAGE_VAR_GRAFANA_URL= "https://d3adc3ii.grafana.net/dashboards"
HOMEPAGE_VAR_GRAFANAPANGOLIN_URL= "https://grafana.d3adc3ii.cc/d/n5bu_kv45/traefik-official-standalone-dashboard"
# Checkmate
HOMEPAGE_VAR_CHECKMATE_ICON= "/icons/checkmate-light.png"
HOMEPAGE_VAR_CHECKMATE_URL= "https://checkmate.d3adc3ii.cc"
# Beszel
HOMEPAGE_VAR_BESZEL_ICON= "/icons/beszel-light.png"
HOMEPAGE_VAR_BESZEL_URL= "https://beszel.d3adc3ii.cc"
HOMEPAGE_VAR_BESZEL_USERNAME= "d3social@pm.me"
HOMEPAGE_VAR_BESZEL_PASSWORD= "LWHAmofkUAagBb8Zx4onH3EiraK8ZCpauKZiGbr5Re"
HOMEPAGE_VAR_BESZEL_VERSION= "2"
HOMEPAGE_VAR_BESZEL_SYSTEMID_pve11= pve11
HOMEPAGE_VAR_BESZEL_SYSTEMID_pve12= pve12
HOMEPAGE_VAR_BESZEL_SYSTEMID_pve13= pve13
HOMEPAGE_VAR_BESZEL_SYSTEMID_pbs= pbs
HOMEPAGE_VAR_BESZEL_FIELDS= ["cpu","memory","disk","network"]
# Scutiny
HOMEPAGE_VAR_SCRUTINY_ICON= "/icons/scrutiny-light.png"
HOMEPAGE_VAR_SCRUTINY_URL= "https://scrutiny.d3adc3ii.cc" 
# ZABBIX
HOMEPAGE_VAR_ZABBIX_ICON= "/icons/zabbix-light.png"
HOMEPAGE_VAR_ZABBIX_URL= "https://zabbix.d3adc3ii.cc/zabbix"
# Checkmk
HOMEPAGE_VAR_CHECKMK_ICON= "/icons/checkmk-light.png"
HOMEPAGE_VAR_CHECKMK_URL= "https://checkmk.d3adc3ii.cc/d3/check_mk"

# Pulse
HOMEPAGE_VAR_PULSEXT_ICON= "sh-proxmox-light"
HOMEPAGE_VAR_PULSEXT_URL= "https://pulse.d3adc3ii.cc"

# NETBOX CLOUD
HOMEPAGE_VAR_NETBOX_ICON= "/icons/netbox-light.png"
HOMEPAGE_VAR_NETBOXCL_URL= "https://wmfk3018.cloud.netboxapp.com"
# NETBOX CONSOLE
HOMEPAGE_VAR_NETBOXCS_URL= "https://console.netboxlabs.com/"# NETBOX CONSOLE
HOMEPAGE_VAR_NETBOXCS_URL= "https://console.netboxlabs.com/"

HOMEPAGE_VAR_NAUTOBOT_URL= "https://nautobot.d3adc3ii.cc/"
HOMEPAGE_VAR_NAUTOBOT_ICON= "/icons/netbox-light.png"


# PHPIPAM
HOMEPAGE_VAR_PHPIPAM_URL= "https://phpipam.d3adc3ii.cc/"
HOMEPAGE_VAR_PHPIPAM_ICON= "/icons/phpipam-light.png"

### APPS ###
# Karakeep
HOMEPAGE_VAR_KARAKEEP_ICON= "/icons/karakeep.png"
HOMEPAGE_VAR_KARAKEEP_URL= "https://kara.d3adc3ii.cc"
# Wallos
HOMEPAGE_VAR_WALLOS_ICON= "/icons/wallos-light.png"
HOMEPAGE_VAR_WALLOS_URL= "https://wallos.d3adc3ii.cc"
# Ommni Tools
HOMEPAGE_VAR_OMNITOOLS_ICON= "sh-omnitools-light"
HOMEPAGE_VAR_OMNITOOLS_URL= "https://omnitools.d3adc3ii.cc"
# Selfhst-icons
HOMEPAGE_VAR_SELFHST_ICON= "sh-selfh-st-light" 
HOMEPAGE_VAR_SELFHST_URL= "https://selfhst-icons.d3adc3ii.cc"

###################   CORP    ##################### 

# Komodo
HOMEPAGE_VAR_KOMODOCORP_URL="http://10.203.1.121:9120"
# Fenrus
HOMEPAGE_VAR_FENRUS_ICON="sh-fenrus"
HOMEPAGE_VAR_FENRUS_URL="http://10.203.1.120:3222"
# PVECORP
HOMEPAGE_VAR_PVECORP_URL="https://10.203.1.113:8006"

### GL1 ###
# PVE11
HOMEPAGE_VAR_PVE11_URL= "https://pve11.d3adc3ii.cc"
HOMEPAGE_VAR_PVE12_URL= "10.10.10.12"
HOMEPAGE_VAR_PVE13_URL= "10.10.10.13"
HOMEPAGE_VAR_GLANCES_PVE11= "http://10.10.10.11:61208"
HOMEPAGE_VAR_GLANCES_PVE12= "http://10.10.10.12:61208"
HOMEPAGE_VAR_GLANCES_PVE13= "http://10.10.10.13:61208"
"""

##

[[stack]]
name = "immich"
[stack.config]
server = "komodo-3"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  immich-server:
    container_name: immich_server
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    # extends:
    #   file: hwaccel.transcoding.yml
    #   service: cpu # set to one of [nvenc, quicksync, rkmpp, vaapi, vaapi-wsl] for accelerated transcoding
    volumes:
      # Do not edit the next line. If you want to change the media storage location on your system, edit the value of UPLOAD_LOCATION in the .env file
      - ${UPLOAD_LOCATION}:/usr/src/app/upload
      - /etc/localtime:/etc/localtime:ro
    env_file:
      - .env
    environment:  
      - PUID=1000
      - PGUID=1000
    security_opt:
  # Prevent escalation of privileges after the container is started
      - no-new-privileges:true
    ports:
      - '2283:2283'
    #depends_on:
    #  - redis
    #  - database
    depends_on:
      redis:
        condition: service_healthy
      database:
        condition: service_started    
    restart: always
    healthcheck:
      disable: false
    labels:
      proxy.aliases: immich
      proxy.immich.port: 2283
      
  immich-machine-learning:
    container_name: immich_machine_learning
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}
    volumes:
      - model-cache:/cache
    security_opt:
  # Prevent escalation of privileges after the container is started
      - no-new-privileges:true
    env_file:
      - .env
    restart: always
    healthcheck:
      disable: false
  redis:
    container_name: immich_redis
    image: docker.io/valkey/valkey:8-bookworm@sha256:42cba146593a5ea9a622002c1b7cba5da7be248650cbb64ecb9c6c33d29794b1
    security_opt:
  # Prevent escalation of privileges after the container is started
      - no-new-privileges:true
    healthcheck:
      test: redis-cli ping || exit 1
    restart: always

  database:
    container_name: immich_postgres
    image: docker.io/tensorchord/pgvecto-rs:pg14-v0.2.0@sha256:739cdd626151ff1f796dc95a6591b55a714f341c737e27f045019ceabf8e8c52
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_DATABASE_NAME}
      POSTGRES_INITDB_ARGS: '--data-checksums'
    security_opt:
  # Prevent escalation of privileges after the container is started
      - no-new-privileges:true
    volumes:
      # Do not edit the next line. If you want to change the database storage location on your system, edit the value of DB_DATA_LOCATION in the .env file
      - ${DB_DATA_LOCATION}:/var/lib/postgresql/data
    restart: always

volumes:
  model-cache:
  postgres:
"""
environment = """
IMMICH_IGNORE_MOUNT_CHECK_ERRORS=true
PGID=1000
PUID=1000
UPLOAD_LOCATION=/mnt/zApps/immich-lib/upload
DB_DATA_LOCATION=./postgres
IMMICH_VERSION=release
DB_PASSWORD=[[IMMICH_DB_PASSWORD]]
POSTGRES_PASSWORD=[[IMMICH_DB_PASSWORD]]
DB_USERNAME: postgres
DB_DATABASE_NAME=immich
"""

##

[[stack]]
name = "jellyfin"
tags = [
  "internal",
  "production",
  "komodo-3"
]
[stack.config]
server = "komodo-3"
project_name = "jellyfin"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  jellyfin:
    image: lscr.io/linuxserver/jellyfin:latest
    container_name: jelly
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Singapore
      - JELLYFIN_PublishedServerUrl=https://jelly.d3adc3ii.site #optional
    volumes:
      - ${DOCKER_DATA}/jellyfin/config:/config
      - ${JELLYFIN_DATA_DIR}/tvshows:/data/tvshows
      - ${JELLYFIN_DATA_DIR}/movies:/data/movies
    ports:
      - 8096:8096
      - 8920:8920 #optional
      - 7359:7359/udp #optional
      - 1900:1900/udp #optional
    restart: unless-stopped
    labels:
      proxy.idle_timeout: 30m
      proxy.jelly.port: 8096
"""
environment = """
JELLYFIN_DATA_DIR=/mnt/zFiles/media

"""

##

[[stack]]
name = "karakeep"
tags = [
  "external",
  "production",
  "komodo-2"
]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
version: '3.8'
services:
  web:
    image: ghcr.io/karakeep-app/karakeep:${KARAKEEP_VERSION:-release}
    restart: unless-stopped
    volumes:
      - ${DOCKER_DATA}/karakeep/data:/data
    ports:
      - 3333:3000
    env_file:
      - .env
    environment:
      MEILI_ADDR: http://meilisearch:7700
      BROWSER_WEB_URL: http://chrome:9222
      DATA_DIR: /data
  chrome:
    image: gcr.io/zenika-hub/alpine-chrome:123
    restart: unless-stopped
    command:
      - --no-sandbox
      - --disable-gpu
      - --disable-dev-shm-usage
      - --remote-debugging-address=0.0.0.0
      - --remote-debugging-port=9222
      - --hide-scrollbars
  meilisearch:
    image: getmeili/meilisearch:v1.13.3
    restart: unless-stopped
    env_file:
      - .env
    environment:
      MEILI_NO_ANALYTICS: "true"
    volumes:
      - meilisearch:/meili_data

volumes:
  meilisearch:
  data:
"""
environment = """
KARAKEEP_VERSION=release
NEXTAUTH_SECRET=[[KARA_NEXTAUTH_SECRET]]
MEILI_MASTER_KEY=[[KARA_MEILI_MASTER_KEY]]
NEXTAUTH_URL='https://kara.d3adc3ii.cc'
OPENAI_API_KEY=[[OPENAI_API_KEY]]
OAUTH_ALLOW_DANGEROUS_EMAIL_ACCOUNT_LINKING= true
OAUTH_WELLKNOWN_URL='https://auth.d3adc3ii.cc/application/o/karakeep/'
OAUTH_CLIENT_SECRET=db64i7QZ2MHMVkjOvZfcOyWTh1y1ECG2XNamIkLXBZxi0UqLfcfvVxYcsQ7nWbZvFeRQBGnJB2vnVqGQgKkUopKGlGooRuGW2R8DnvxoORYAVWhW77x5PVhwlOB0Cr9s
OAUTH_CLIENT_ID=D8rw3kVA932oWoPiLud8z5FgomI3sXT4oOTYMBIr
OAUTH_PROVIDER_NAME= authentik
"""

##

[[stack]]
name = "loggifly"
tags = ["internal", "monitoring"]
[stack.config]


##

[[stack]]
name = "lunalytics"
tags = ["testing"]
[stack.config]
server = "komodo-3"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
# docker-compose.yml
services:
  lunalytics:
    image: ksjaay/lunalytics:latest
    container_name: lunalytics
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - '2308:2308'
    volumes:
      - ${DOCKER_DATA}/lunalytics/data:/app/data
      - ${DOCKER_DATA}/lunalytics/logs:/app/logs
"""
environment = """
PGUI=1000
PUID=1000
"""

##

[[stack]]
name = "mailrise"
tags = ["komodo-3"]
[stack.config]
server = "komodo-3"
file_contents = """
services:
  mailrise:
    image: yoryan/mailrise:latest
    container_name: mailrise
    ports:
      - '8025:8025'
    restart: unless-stopped
    volumes:
      -  /mnt/zApps/mailrise/mailrise.conf:/etc/mailrise.conf:ro
"""
environment = """

"""

##

[[stack]]
name = "netalertx"
tags = [
  "internal",
  "monitoring",
  "komodo-1"
]
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  netalertx:
    container_name: netalertx
    image: "ghcr.io/jokob-sk/netalertx:latest"      
    network_mode: "host"     
    restart: unless-stopped
    volumes:
      - ${DATA_DIR}/config:/app/config
      - ${DATA_DIR}/db:/app/db      
      - ${DATA_DIR}/logs:/app/log
      - type: tmpfs
        target: /app/api
    env_file:
      - .env
    labels:
      proxy.port: 20184
"""
environment = """
DATA_DIR=/mnt/zApps/netalertx
PUID=1000
PGID=1000
TZ=Asia/Singapore
PORT=20184
"""

##

[[stack]]
name = "ntfy"
tags = [
  "internal",
  "monitoring",
  "komodo-2"
]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  ntfy:
    image: binwiederhier/ntfy
    container_name: ntfy
    command:
      - serve
    environment:
      - TZ=Asia/Singapore    # optional: set desired timezone
    user: 1000:1000 # optional: replace with your own user/group or uid/gid
    env_file:
      - .env
    volumes:
      - /var/cache/ntfy:/var/cache/ntfy
      - ${NTFY_DATA_DIR}:/etc/ntfy
    ports:
      - 8193:80
    healthcheck: # optional: remember to adapt the host:port to your environment
        test: ["CMD-SHELL", "wget -q --tries=1 http://localhost:80/v1/health -O - | grep -Eo '\"healthy\"\\s*:\\s*true' || exit 1"]
        interval: 60s
        timeout: 10s
        retries: 3
        start_period: 40s
    restart: unless-stopped
"""
environment = """
NTFY_DATA_DIR=/mnt/zApps/ntfy
"""

##

[[stack]]
name = "nzbget"
tags = ["internal", "komodo-3"]
[stack.config]
server = "komodo-3"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  nzbget:
    image: lscr.io/linuxserver/nzbget:latest
    container_name: nzbget
    env_file:
      - .env
    volumes:
      - ${DOCKER_DATA}/nzb/config:/config
      - ${DOCKER_DATA}/nzb/downloads:/downloads #optional
    ports:
      - 6789:6789
    restart: unless-stopped
    labels:
      proxy.idle_timeout: 10m
"""
environment = """
NZBGET_USER= [[NZBGET_USER]]
NZBGET_PASS= [[NZBGET_PASS]]
PUID= [[PUID]]
PGID= [[PGID]]
TZ= [[TZ]]
"""

##

[[stack]]
name = "phpipam"
tags = ["internal", "komodo-3"]
[stack.config]
server = "komodo-3"
project_name = "phpipam"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  phpipam-web:
    image: phpipam/phpipam-www:latest
    ports:
      - "8087:80"
    restart: always
    env_file:
      - .env
    volumes:
      - phpipam-logo:/phpipam/css/images/logo
      - phpipam-ca:/usr/local/share/ca-certificates:ro
    depends_on:
      - phpipam-mariadb

  phpipam-cron:
    image: phpipam/phpipam-cron:latest
    environment:
      - TZ=Europe/London
      - IPAM_DATABASE_HOST=phpipam-mariadb
      - IPAM_DATABASE_PASS=password
      - SCAN_INTERVAL=1h
    restart: always
    volumes:
      - phpipam-ca:/usr/local/share/ca-certificates:ro
    depends_on:
      - phpipam-mariadb

  phpipam-mariadb:
    image: mariadb:latest
    environment:
      - MYSQL_ROOT_PASSWORD=password
    restart: always
    volumes:
      - phpipam-db-data:/var/lib/mysql

volumes:
  phpipam-db-data:
  phpipam-logo:
  phpipam-ca:
"""
environment = """

      - TZ=America/Chicago
      - IPAM_DATABASE_HOST=phpipam-mariadb
      - IPAM_DATABASE_PASS=password
      - IPAM_DATABASE_WEBHOST=%
"""

##

[[stack]]
name = "prowlarr"
tags = ["internal", "komodo-2"]
[stack.config]
server = "komodo-2"
links = [
  "https://prowlarr.d3adc3ii.site/"
]
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  prowlarr:
    image: lscr.io/linuxserver/prowlarr:latest
    container_name: prowlarr
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
    volumes:
      - ${DOCKER_DATA}/prowlarr/data:/config
    ports:
      - 9696:9696
    restart: unless-stopped
    labels:
      proxy.idle_timeout: 1h
"""

##

[[stack]]
name = "scrutiny"
tags = ["komodo-3"]
[stack.config]
server = "komodo-3"
links = [
  "https://scrutiny.d3adc3ii.cc/web/dashboard"
]
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  scrutiny-monitoring: # A common network for all monitoring services to communicate into
    external: true
  scrutiny-notification: # To Gotify or another Notification service
    external: true

services:
  influxdb:
    container_name: influxdb
    image: influxdb:2.1-alpine
    env_file:
      - .env
    user: 1000:1000
    ports:
      - 8086:8086
    volumes:
      - ${DOCKER_DATA}/scrutiny/influxdb2/db:/var/lib/influxdb2
      - ${DOCKER_DATA}/scrutiny/influxdb2/config:/etc/influxdb2
    restart: unless-stopped
    networks:
      - scrutiny-monitoring

  scrutiny:
    container_name: scrutiny
    image: ghcr.io/analogj/scrutiny:master-web
    ports:
      - 8785:8080
    volumes:
      - ${DOCKER_DATA}/scrutiny/config:/opt/scrutiny/config
    env_file:
      - .env
      # Optional but highly recommended to notify you in case of a problem
     # - SCRUTINY_NOTIFY_URLS=["http://gotify:80/message?token=a-gotify-token"]
    depends_on:
      - influxdb
    restart: unless-stopped
    networks:
      - scrutiny-notification
      - scrutiny-monitoring
"""
environment = """
PGID= 1000 
PUID= 1000
DOCKER_INFLUXDB_INIT_MODE=setup
DOCKER_INFLUXDB_INIT_USERNAME=Admin
DOCKER_INFLUXDB_INIT_PASSWORD= 'qA6otE2(raC=MDh$ZN%tNulHp6iYs|xv}l&IwVWPzZvn+Tvm399+2w#V$P'
#DOCKER_INFLUXDB_INIT_PASSWORD= [[SCRUTINY_DOCKER_INFLUXDB_INIT_PASSWORD]]
DOCKER_INFLUXDB_INIT_ORG=homelab
DOCKER_INFLUXDB_INIT_BUCKET=scrutiny
DOCKER_INFLUXDB_INIT_ADMIN_TOKEN= '6-zG/W<%eE-)rG6Gh9@WY^v#+y3KN()tf2}UNkXN=j{lDnu+P7+Kl!$G<(x['
#DOCKER_INFLUXDB_INIT_ADMIN_TOKEN= [[SCRUTINY_DOCKER_INFLUXDB_INIT_ADMIN_TOKEN]]
SCRUTINY_WEB_INFLUXDB_HOST=influxdb
SCRUTINY_WEB_INFLUXDB_PORT=8086
SCRUTINY_WEB_INFLUXDB_TOKEN= '6-zG/W<%eE-)rG6Gh9@WY^v#+y3KN()tf2}UNkXN=j{lDnu+P7+Kl!$G<(x['
#SCRUTINY_WEB_INFLUXDB_TOKEN= [[SCRUTINY_WEB_INFLUXDB_TOKEN]]
SCRUTINY_WEB_INFLUXDB_ORG=homelab
SCRUTINY_WEB_INFLUXDB_BUCKET=scrutiny
"""

##

[[stack]]
name = "selfhst-icons"
[stack.config]
server = "komodo-3"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  selfhst-icons:
    image: ghcr.io/selfhst/icons:latest
    restart: unless-stopped
    ports:
      - 4050:4050
    labels:
      proxy.idle_timeout: 10m
"""

##

[[stack]]
name = "shellhub"
[stack.config]
server = "komodo-1"
project_name = "shellhub"
files_on_host = true
run_directory = "/home/d3/shellhub"
file_paths = [
  "docker-compose.agent.yml",
  "docker-compose.autossl.yml",
  "docker-compose.dev.yml",
  "docker-compose.enterprise.yml",
  "docker-compose.test.yml",
  "docker-compose.yml"
]

##

[[stack]]
name = "silverbullet"
tags = ["external", "komodo-2"]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  silverbullet:
    image: ghcr.io/silverbulletmd/silverbullet:v2
    container_name: silverbullet
    restart: unless-stopped
    env_file:
      - .env
    volumes:
      - ${DOCKER_DATA}/silverbullet/space:/space
    ports:
      - 3718:3000
    labels:
      proxy.exclude: true
"""
environment = """
SB_USER=[[SILVERBULLET_USER]]
PGID=1000
PUID=1000
"""

##

[[stack]]
name = "speedtest-tracker"
tags = ["internal", "testing"]
[stack.config]
server = "komodo-1"
project_name = "speedtest-tracker"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  speedtest-tracker:
    image: lscr.io/linuxserver/speedtest-tracker:latest
    container_name: speedtest-tracker
    env_file:
      - .env
    environment:
      - DB_CONNECTION=mariadb
      - DB_HOST=db
      - DB_PORT=3306
      - DB_DATABASE=speedtest_tracker
      - DB_USERNAME=speedtest_tracker
      - DB_PASSWORD=password
    volumes:
      - ${DOCKER_DATA}/speedtest-tracker/data:/config
    ports:
      - 8785:80
    restart: unless-stopped
    depends_on:
      - db
    labels:
        proxy.aliases: speedtest
        proxy.port: 8785
  db:
        image: mariadb:11
        restart: always
        env_file:
          - .env
        environment:
            - MYSQL_RANDOM_ROOT_PASSWORD=true
        volumes:
            - speedtest-db:/var/lib/mysql
        healthcheck:
            test: ["CMD", "healthcheck.sh", "--connect", "--innodb_initialized"]
            interval: 5s
            retries: 3
            timeout: 5s
volumes:
  speedtest-db:
"""
environment = """
APP_DEBUG=true
PUID=1000
PGID=1000
DISPLAY_TIMEZONE=Asia/Singapore #optional
PRUNE_RESULTS_OLDER_THAN=10 #optional

SPEEDTEST_SCHEDULE= @hourly
SPEEDTEST_SERVERS= 5935

APP_KEY="base64:KbesVaBvct5cPnyLQBmWgFdY6u7DAVmoo8YFO8EV3W8="
DB_DATABASE=speedtest_tracker
APP_URL= http://192.168.2.31:8785
#DB_CONNECTION=mariadb
#DB_HOST=db
#DB_PORT=3306
#DB_DATABASE=speedtest_tracker
#DB_USERNAME=speedtest_tracker
#DB_PASSWORD=sVaBvct5cPnyLQBmWgFdY6u7DA
MYSQL_DATABASE=speedtest_tracker
MYSQL_USER=speedtest_tracker
MYSQL_PASSWORD=password
"""

##

[[stack]]
name = "termix"
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  termix:
    image: ghcr.io/lukegus/termix:latest
    container_name: termix
    restart: unless-stopped
    ports:
      - "8282:8080"
    volumes:
      - ${DOCKER_DATA}/termix/data:/app/data
    env_file:
      - .env
"""
environment = """
SALT: "tJ,V_^12phQ=66k'<v*7G?-Qw:/o)dom"
PORT: "8080"
"""

##

[[stack]]
name = "true-command"
tags = ["komodo-3"]
[stack.config]
server = "komodo-3"
file_contents = """
services:
  true-command:
    container_name: true-command
    image: ixsystems/truecommand:latest
    restart: unless-stopped
    volumes:
      - ${DOCKER_DATA}/truecommand:/data
    ports:
      - 8880:80
      - 4443:443
    labels:  
      proxy.idle_timeout: 15m
"""

##

[[stack]]
name = "uptime-kuma"
tags = [
  "external",
  "monitoring",
  "komodo-3"
]
[stack.config]
server = "komodo-3"
links = ["https://uptime.d3adc3ii.cc/"]
project_name = "uptime-kuma"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  uptime-kuma:
    image: louislam/uptime-kuma:1
    container_name: uptime-kuma
    env_file:
      - .env
    volumes:
      - ${DOCKER_DATA}/uptime-kuma/data:/app/data
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 3111:3001
    restart: always
    labels:
      proxy.exclude: true
"""
environment = """
PUID=1000
PGID=1000
"""

##

[[stack]]
name = "wallos"
tags = [
  "external",
  "production",
  "komodo-3"
]
[stack.config]
server = "komodo-3"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  wallos:
    container_name: wallos
    image: bellamy/wallos:latest
    ports:
      - "8282:80/tcp"
    env_file:
      - .env
    volumes:
      - ${DATA_DIR}/db:/var/www/html/db'
      - ${DATA_DIR}/logos:/var/www/html/images/uploads/logos'
    restart: unless-stopped
    labels:
      proxy.idle_timeout: 15m
"""
environment = """
TZ= 'Asia/Singapore'
DATA_DIR=/mnt/zApps/wallos
PUID=1000
PGID=1000
"""

##

[[deployment]]
name = "apprise"
[deployment.config]
server = "komodo-3"
image.type = "Image"
image.params.image = "caronc/apprise:latest"
poll_for_updates = true
auto_update = true
network = "bridge"
ports = """
8000:8000
"""
volumes = """
/mnt/zApps/apprise_api/config:/opt/apprise/config
/mnt/zApps/apprise_api/plugin:/opt/apprise/plugin
/mnt/zApps/apprise_api/attach:/opt/apprise/attach
"""
environment = """
PUID=1000
PGID=1000
APPRISE_STATEFUL_MODE=simple
APPRISE_WORKER_COUNT=1
"""

##

[[deployment]]
name = "nessus"
tags = ["internal", "testing"]
[deployment.config]
server = "komodo-2"
image.type = "Image"
image.params.image = "tenable/nessus:latest-ubuntu"

##

[[deployment]]
name = "newt1"
tags = ["external", "production"]
[deployment.config]
server = "komodo-1"
image.type = "Image"
image.params.image = "fosrl/newt"
poll_for_updates = true
auto_update = true
restart = "unless-stopped"
environment = """
  PANGOLIN_ENDPOINT=https://pangolin.d3adc3ii.cc
  NEWT_ID=[[NEWT_ID1]]
  NEWT_SECRET=[[NEWT_SECRET1]]
"""

##

[[deployment]]
name = "statementsensei"
tags = ["internal", "testing"]
[deployment.config]
server = "komodo-2"
image.type = "Image"
image.params.image = "benjaminawd/statementsensei:latest"
poll_for_updates = true
auto_update = true
network = "bridge"
ports = """
8501:8501
"""
environment = """
  PDF_PASSWORD= [[PDF_PASSWORD]]
"""
labels = """
caddy: statement.d3adc3ii.site
caddy.reverse_proxy: "{{upstreams 8501}}"
"""

##

[[deployment]]
name = "twingate"
tags = ["external", "production"]
[deployment.config]
server = "komodo-2"
image.type = "Image"
image.params.image = "twingate/connector:latest"
poll_for_updates = true
auto_update = true
restart = "unless-stopped"
environment = """
  TWINGATE_NETWORK=d3net
  TWINGATE_ACCESS_TOKEN=eyJhbGciOiJFUzI1NiIsImtpZCI6Inp3dkU1dHpJZzV4X2pSVEU4RTFWQll6MW0tX2g1dXlMZlhTV1VSS1BEVE0iLCJ0eXAiOiJEQVQifQ.eyJudCI6IkFOIiwiYWlkIjoiNTExMjE5IiwiZGlkIjoiMjE5MTEwMCIsImp0aSI6ImIxZjU3N2FkLTZmNDItNDYyYS05ZGIzLTY1NTE5ZmQyMTJlNCIsImlzcyI6InR3aW5nYXRlIiwiYXVkIjoiZDNuZXQiLCJleHAiOjE3NDYxNDQ5MDAsImlhdCI6MTc0NjE0MTMwMCwidmVyIjoiNCIsInRpZCI6IjEwMzU2NCIsInJudyI6MTc0NjE0MTU3OCwicm5ldGlkIjoiMTM1OTMxIn0.OxT4qXnqonLPGb1GwJTRcYoSwZG16x2JGA_Xu2pOo0dZH3jpqfd1SkjWy8JjcVePboTum2e0WEdNu4SFcJUy_A
  TWINGATE_REFRESH_TOKEN=mrNJNc7hirY3gO3-q9l6dnN_YjYl-8q79XRXg1ffZstYm8EYyH6xNXMIVviMaQ-2-GAa4wuSMv1J5ebEf9KvzIK94jmq7j9QGPH2Tr7ZnjlYADuKrEpKUkrmnbrROkgQy6nzWg
  TWINGATE_LOG_ANALYTICS=v2
"""

##

[[repo]]
name = "diiihl"
[repo.config]
server = "komodo-1"
builder = "local"
git_account = "d3hl"
repo = "d3hl/dIIIhl"

##

[[repo]]
name = "diiihl-3"
[repo.config]
server = "komodo-3"
builder = "local"
git_account = "d3hl"
repo = "d3hl/dIIIhl"

##

[[procedure]]
name = "pull repo and deploy homepage"

[[procedure.config.stage]]
name = "Stage 4"
enabled = true
executions = [
  { execution.type = "CommitSync", execution.params.sync = "sync", enabled = true }
]

[[procedure.config.stage]]
name = "Stage 1"
enabled = true
executions = [
  { execution.type = "PullRepo", execution.params.repo = "diiihl", enabled = true }
]

[[procedure.config.stage]]
name = "Stage 3"
enabled = true
executions = [
  { execution.type = "DestroyStack", execution.params.stack = "homepage", execution.params.services = [], execution.params.remove_orphans = false, enabled = true }
]

[[procedure.config.stage]]
name = "Stage 3"
enabled = true
executions = [
  { execution.type = "DeployStack", execution.params.stack = "homepage", execution.params.services = [], enabled = true }
]

##

[[alerter]]
name = "discord-webhook"
[alerter.config]
enabled = true
endpoint.type = "Custom"
endpoint.params.url = "http://10.10.10.32:7000"
alert_types = [
  "ServerUnreachable",
  "ServerMem",
  "ServerCpu",
  "ServerDisk",
  "StackAutoUpdated",
  "StackStateChange",
  "ContainerStateChange",
  "StackImageUpdateAvailable",
  "DeploymentAutoUpdated",
  "DeploymentImageUpdateAvailable",
  "ResourceSyncPendingUpdates",
  "AwsBuilderTerminationFailed",
  "BuildFailed",
  "RepoBuildFailed"
]

##

[[builder]]
name = "local"
[builder.config]
type = "Server"
params.server_id = "komodo-1"

##

[[resource_sync]]
name = "sync"
[resource_sync.config]
repo = "d3hl/dIIIhl"
git_account = "d3hl"
resource_path = ["komodo/resources/main.toml"]
managed = true
include_user_groups = true

##

[[resource_sync]]
name = "var"
[resource_sync.config]
repo = "d3hl/dIIIhl"
git_account = "d3hl"
resource_path = ["komodo/resources/var.toml"]
managed = true
include_resources = false
include_variables = true