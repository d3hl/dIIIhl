[[server]]
name = "komodo-1"
tags = ["10.10.10.25"]
[server.config]
address = "https://10.10.10.25:8120"
region = "Singapore"
enabled = true

##

[[server]]
name = "komodo-2"
tags = ["10.10.10.26"]
[server.config]
address = "https://10.10.10.26:8120"
region = "Singapore"
enabled = true

##

[[server]]
name = "komodo-28"
[server.config]
address = "https://10.10.10.28:8120"
enabled = true

##

[[server]]
name = "komodo-3"
tags = ["10.10.10.27"]
[server.config]
address = "https://10.10.10.27:8120"
region = "Singapore"
enabled = true

##

[[server]]
name = "pangolin"
[server.config]
address = "https://45.127.32.141:8120"
region = "Orange"
enabled = true

##

[[stack]]
name = "actual-budget"
tags = [
  "internal",
  "production",
  "komodo-2"
]
[stack.config]
server = "komodo-2"
project_name = "actual-budget"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  actual_server:
    image: docker.io/actualbudget/actual-server:latest
    ports:
      - '5006:5006'
    env_file:
      - .env  
    volumes:
      - ${DOCKER_DATA}/actualbudget:/data
    healthcheck:
      # Enable health check for the instance
      test: ['CMD-SHELL', 'node src/scripts/health-check.js']
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 20s
    restart: unless-stopped
    labels:
      proxy.aliases: actual
      proxy.actual.port: 5006
      proxy.idle_timeout: 30m
"""
environment = """
PUID=1000
PGID=1000
      # Uncomment any of the lines below to set configuration options.
      # - ACTUAL_HTTPS_KEY=/data/selfhost.key
      # - ACTUAL_HTTPS_CERT=/data/selfhost.crt
      # - ACTUAL_PORT=5006
      # - ACTUAL_UPLOAD_FILE_SYNC_SIZE_LIMIT_MB=20
      # - ACTUAL_UPLOAD_SYNC_ENCRYPTED_FILE_SYNC_SIZE_LIMIT_MB=50
      # - ACTUAL_UPLOAD_FILE_SIZE_LIMIT_MB=20
      # See all options and more details at https://actualbudget.github.io/docs/Installing/Configuration
      # !! If you are not using any of these options, remove the 'environment:' tag entirely.
"""

##

[[stack]]
name = "authentik"
tags = [
  "external",
  "production",
  "komodo-1"
]
[stack.config]
server = "komodo-1"
links = ["https://auth.d3adc3ii.cc/"]
project_name = "authentik"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  postgresql:
    image: docker.io/library/postgres:16-alpine
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}"]
      start_period: 20s
      interval: 30s
      retries: 5
      timeout: 5s
    volumes:
      - database:/var/lib/postgresql/data
    environment:
      POSTGRES_PASSWORD: ${PG_PASS}
      POSTGRES_USER: ${PG_USER}
      POSTGRES_DB: ${PG_DB}
    env_file:
      - .env
    labels:
      proxy.exclude: true
  redis:
    image: docker.io/library/redis:alpine
    command: --save 60 1 --loglevel warning
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep PONG"]
      start_period: 20s
      interval: 30s
      retries: 5
      timeout: 3s
    volumes:
      - redis:/data
  server:
    image: ${AUTHENTIK_IMAGE:-ghcr.io/goauthentik/server}:${AUTHENTIK_TAG:-2025.6.4}
    restart: unless-stopped
    command: server
    container_name: authentik
    networks:
      - default
      - d3internal
    environment:
      AUTHENTIK_SECRET_KEY: ${AUTHENTIK_SECRET_KEY}
      AUTHENTIK_REDIS__HOST: redis
      AUTHENTIK_POSTGRESQL__HOST: postgresql
      AUTHENTIK_POSTGRESQL__USER: ${PG_USER:-authentik}
      AUTHENTIK_POSTGRESQL__NAME: ${PG_DB:-authentik}
      AUTHENTIK_POSTGRESQL__PASSWORD: ${PG_PASS}
    volumes:
      - ${DOCKER_DATA}/authentik/media:/media
      - ${DOCKER_DATA}/authentik/custom-templates:/templates
    env_file:
      - .env
    ports:
      - "${COMPOSE_PORT_HTTP:-9000}:9000"
      - "${COMPOSE_PORT_HTTPS:-9443}:9443"
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
    labels:
      - homepage.group=Domain
      - homepage.name=Authentik Admin
      - homepage.icon=sh-authentik-light
      - homepage.href=https://auth.d3adc3ii.cc
      - homepage.widget.type=authentik
      - homepage.widget.url=https://auth.d3adc3ii.cc
      - homepage.widget.key="ZnhLrOvUoWZfHcQpFrteQVekOjpGQh48lXEVFn34HvGtT8eJoyhgaNYWb2mI"
  worker:
    image: ${AUTHENTIK_IMAGE:-ghcr.io/goauthentik/server}:${AUTHENTIK_TAG:-2025.6.2}
    restart: unless-stopped
    command: worker
    environment:
      AUTHENTIK_SECRET_KEY: ${AUTHENTIK_SECRET_KEY}
      AUTHENTIK_REDIS__HOST: redis
      AUTHENTIK_POSTGRESQL__HOST: postgresql
      AUTHENTIK_POSTGRESQL__USER: ${PG_USER}
      AUTHENTIK_POSTGRESQL__NAME: ${PG_DB}
      AUTHENTIK_POSTGRESQL__PASSWORD: ${PG_PASS}
    # `user: root` and the docker socket volume are optional.
    # See more for the docker socket integration here:
    # https://goauthentik.io/docs/outposts/integrations/docker
    # Removing `user: root` also prevents the worker from fixing the permissions
    # on the mounted folders, so when removing this make sure the folders have the correct UID/GID
    # (1000:1000 by default)
    user: root
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ${AUTHENTIK_DATA_DIR}/media:/media
      - ./certs:/certs
      - ${AUTHENTIK_DATA_DIR}/custom-templates:/templates
    env_file:
      - .env
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
    labels:
       proxy.exclude: true
volumes:
  database:
    driver: local
  redis:
    driver: local
"""
environment = """
PG_USER= authentik
PG_DB= authentik
AUTHENTIK_SECRET_KEY= [[AUTHENTIK_SECRET_KEY]]
PG_PASS= [[AUTHENTIK_PG_PASS]]
# SMTP Host Emails are sent to
AUTHENTIK_EMAIL__HOST=localhost
AUTHENTIK_EMAIL__PORT=25
# Use StartTLS
AUTHENTIK_EMAIL__USE_TLS=false
# Use SSL
AUTHENTIK_EMAIL__USE_SSL=false
AUTHENTIK_EMAIL__TIMEOUT=10
# Email address authentik will send from, should have a correct @domain
AUTHENTIK_EMAIL__FROM=authentik@localhost
COMPOSE_PORT_HTTP=9111
COMPOSE_PORT_HTTPS=9444
"""

##

[[stack]]
name = "beszel"
tags = [
  "komodo-1",
  "external",
  "monitoring",
  "beszel"
]
[stack.config]
server = "komodo-1"
file_contents = """
services:
  beszel:
    image: henrygd/beszel:latest
    container_name: beszel
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - 8090:8090
    volumes:
      - ${DOCKER_DATA}/beszel/beszel_data:/beszel_data
      - ${DOCKER_DATA}/beszel/beszel_socket:/beszel_socket
  beszel-agent:
    image: henrygd/beszel-agent:latest
    container_name: beszel-agent
    restart: unless-stopped
    network_mode: host
    volumes:
      - ${DOCKER_DATA}/beszel/beszel_socket:/beszel_socket
      - /var/run/docker.sock:/var/run/docker.sock:ro
    env_file:
      - .env
    environment:
      LISTEN: /beszel_socket/beszel.sock
      # Do not remove quotes around the key
      KEY: 'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIG+PtfmPHdKiaE+gbET/6wZeFSnsUEgOXpKM1qJ4gCPp'
"""
environment = """
PGID=1000
PUID=1000
"""

##

[[stack]]
name = "beszel-agent-k2"
tags = ["agent", "komodo-2", "beszel"]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  beszel-agent:
    image: "henrygd/beszel-agent"
    container_name: "beszel-agent"
    restart: unless-stopped
    network_mode: host
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # monitor other disks / partitions by mounting a folder in /extra-filesystems
      # - /mnt/disk/.beszel:/extra-filesystems/sda1:ro
    environment:
      LISTEN: 45876
      KEY: "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIG+PtfmPHdKiaE+gbET/6wZeFSnsUEgOXpKM1qJ4gCPp"
"""

##

[[stack]]
name = "bookstack"
tags = ["komodo-3", "external"]
[stack.config]
server = "komodo-28"
links = [
  "https://bookstack.d3adc3ii.cc"
]
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  bookstack:
    image: lscr.io/linuxserver/bookstack:latest
    container_name: bookstack
    env_file:
      - .env
    environment:
      - PUID=1000
      - PGID=1000
      - DB_PORT=3306
      - APP_THEME=custom
    volumes:
      - ${DOCKER_DATA}/bookstack/config:/config
    ports:
      - 6875:80
    restart: unless-stopped
    labels:
      - homepage.group=Applications
      - homepage.name=bookstack
      - homepage.icon=sh-bookstack-light
      - homepage.href=https://bookstack.d3adc3ii.cc/
  mariadb:
    image: lscr.io/linuxserver/mariadb:latest
    container_name: mariadb
    env_file:
      - .env
    environment:
      - PUID=1000
      - PGID=1000
    volumes:
      - ${DOCKER_DATA}/bookstack/mariadb/config:/config
    ports:
      - 3306:3306
    restart: unless-stopped
"""
environment = """
TZ=Asia/Singapore
QUEUE_CONNECTION=database
DB_DATABASE=bookstackdb
DB_HOST=mariadb
DB_USERNAME=d3
DB_PASSWORD=USCLZHFZZuT7NFAPVo84bdGTRsDB7v7A
MYSQL_PASSWORD=USCLZHFZZuT7NFAPVo84bdGTRsDB7v7A
APP_URL=https://bookstack.d3adc3ii.cc
APP_KEY=base64:5hfLcDEkhQzRlsTu5xLg7+1xRH4PH9QKacJY65gDQpU=
MYSQL_DATABASE=bookstackdb
MYSQL_USER=d3
MYSQL_ROOT_PASSWORD=USCLZHFZZuT7NFAPVo84bdGTRsDB7v7A123
MYSQL_PASSWORD=USCLZHFZZuT7NFAPVo84bdGTRsDB7v7A
"""

##

[[stack]]
name = "caddy"
tags = [
  "internal",
  "production",
  "core",
  "komodo-1"
]
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  caddy: 
    name: caddy
    ipam:
      driver: default  
    
# Main Caddy
services:
  caddy:
    image: homeall/caddy-reverse-proxy-cloudflare:latest
    networks:
      - caddy
    ports:
      - 80:80
      - 443:443
      - "443:443/udp"
    env_file:
      - .env
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ${DOCKER_DATA}/caddy/data:/data
      - ${DOCKER_DATA}/caddy/config/:/config/caddy  #ðŸ‘ˆ where to save configs 
    restart: unless-stopped
    extra_hosts:
      - host.docker.internal:host-gateway

# Caddy-config container
  caddy-config:
    container_name: caddy-config
    image: traefik/whoami:latest
    networks:
      - caddy
    restart: always
    env_file:
      - .env
    labels:
    #############################################
    # Settings and snippets to get things working
    # You shouldn't need to modify this normally
    # Custom settings and definitions are below
    #############################################

      #### Global Settings ####
      caddy_0.email: ${CADDY_EMAIL}
      caddy_0.auto_https: prefer_wildcard

      #### Snippets ####
      # Get wildcard certificate
      caddy_1: (wildcard)
      #caddy_1.acme_dns: "cloudflare ${CF_API_TOKEN}" 
      caddy_1.tls.dns: "cloudflare ${CF_API_TOKEN}"
      caddy_1.tls.resolvers: 1.1.1.1 1.0.0.1
      caddy_1.handle.abort: ""

      # Skip TLS verify for backend with self-signed HTTPS
      caddy_3: (https)
      caddy_3.transport: http
      caddy_3.transport.tls: ""
      caddy_3.transport.tls_insecure_skip_verify: ""

    ###########################################
    # Custom settings. Modify things below ðŸ‘‡:
    # Make sure they have unique label numbers
    ###########################################

      # Custom global settings, add/edit as needed
      # caddy_0.log: default
      # caddy_0.log.format: console

      # Uncomment this during testing to avoid hitting rate limit.
      # It will try to obtain SSL from Let's Encrypt's staging endpoint.
      # acme_ca: "https://acme-staging-v02.api.letsencrypt.org/directory" # ðŸ‘ˆ Staging

      ## Setup wildcard sites
      caddy_10: "*.d3adc3ii.site"   #ðŸ‘ˆ Change to your domain
      caddy_10.import: wildcard

      # Caddy Admin Endpoint and Metrics
      caddy_20: :2020
      #caddy_20.admin: "0.0.0.0:2019"
      #caddy_20.admin.origin: "caddy.d3adc3ii.site"
      caddy_20.handle: /reverse_proxy/upstreams
      caddy_20.handle.reverse_proxy: localhost:2019
      caddy_20.handle.reverse_proxy.header_up: Host localhost:2019
    

      # Add our first site, which this container itself
      caddy_99: whoami.d3adc3ii.site                       #ðŸ‘ˆ Subdomain using wildcard cert
      caddy_99.reverse_proxy: "{{upstreams 80}}"         #ðŸ‘ˆ Container port

      # For non-docker sites see https://gist.github.com/omltcat/241ef622070ca0580f2876a7cfa7de67
      # e.g.: Pi-Hole on another machine in the same LAN
      caddy_100: netalertx.d3adc3ii.site                      
      caddy_100.reverse_proxy: 192.168.2.31:20184

      caddy_101: pve.d3adc3ii.site                      
      caddy_101.reverse_proxy: 192.168.2.11:8006
      caddy_101.reverse_proxy.transport: http
      caddy_101.reverse_proxy.transport.tls_insecure_skip_verify: ""


      caddy_102: opn.d3adc3ii.site                      
      caddy_102.reverse_proxy: 192.168.2.1:2184
      caddy_102.reverse_proxy.transport: http
      caddy_102.reverse_proxy.transport.tls: ""
      caddy_102.reverse_proxy.transport.versions: 1.1 1.2
      caddy_102.reverse_proxy.transport.tls_insecure_skip_verify: ""

      caddy_103: truenas.d3adc3ii.site                      
      caddy_103.reverse_proxy: 192.168.2.7
      caddy_103.reverse_proxy.transport: http
      caddy_103.reverse_proxy.transport.tls_insecure_skip_verify: ""

      caddy_104: pbs.d3adc3ii.site   
      caddy_104.reverse_proxy: 192.168.2.35:8007
      caddy_104.reverse_proxy.transport: http
      caddy_104.reverse_proxy.transport.tls_insecure_skip_verify: ""

      caddy_105: ns0.d3adc3ii.site                      
      caddy_105.reverse_proxy: 192.168.2.5:5380
      caddy_106: stash.d3adc3ii.site                      
      caddy_106.reverse_proxy: 192.168.2.26:9999
      caddy_107: ha.d3adc3ii.site                      
      caddy_107.reverse_proxy: 192.168.99.5:8123    
      #caddy_108: jelly.d3adc3ii.site                      
      #caddy_108.reverse_proxy: 192.168.2.33:8096
      caddy_109: semaphore.d3adc3ii.site                      
      caddy_109.reverse_proxy: 192.168.2.28:3000            
      caddy_110: aria.d3adc3ii.site                      
      caddy_110.reverse_proxy: 192.168.2.16:6880  
      caddy_111: pulse.d3adc3ii.site                      
      caddy_111.reverse_proxy: 192.168.2.36:7655     
      caddy_112: backrest.d3adc3ii.site                      
      caddy_112.reverse_proxy: 192.168.2.35:9898
      caddy_113: actual.d3adc3ii.site                      
      caddy_113.reverse_proxy: 192.168.2.32:5006
      # wazuh
      caddy_114: wazuh.d3adc3ii.site                      
      caddy_114.reverse_proxy: 192.168.2.30:443
      caddy_114.reverse_proxy.transport: http
      caddy_114.reverse_proxy.transport.tls_insecure_skip_verify: ""
      # guaca
      caddy_115: guaca.d3adc3ii.site                      
      caddy_115.reverse_proxy: 192.168.2.20
      #caddy_116: checkmate.d3adc3ii.site                      
      #caddy_116.reverse_proxy: 192.168.2.33:52345  
      #caddy_117: checkmate2.d3adc3ii.site                      
      #caddy_117.reverse_proxy: 192.168.2.32:59232
      #caddy_118: checkmate3.d3adc3ii.site                      
      #caddy_118.reverse_proxy: 192.168.2.33:59232    

      # e.g. OpenMediaVault on the host machine, with self-signed https at port 4430
      #caddy_101: omv.example.com                         #ðŸ‘ˆ Subdomain using wildcard cert
      #caddy_101.reverse_proxy: host.docker.internal:4430 #ðŸ‘ˆ Port on host machine
      #caddy_101.reverse_proxy.import: https              #ðŸ‘ˆ Allow self-signed cert between OMV and Caddy
      #caddy_101.import: auth                             #ðŸ‘ˆ Enable protection by Authelia
"""
environment = """
PUID= [[PUID]]
PGID= [[PGID]]
CADDY_INGRESS_NETWORKS=caddy
CF_API_TOKEN= [[CF_API_TOKEN]]
CADDY_EMAIL= d3tech@pm.me
"""

##

[[stack]]
name = "discord-alerter"
[stack.config]
server = "komodo-2"
repo = "foxxmd/deploy-discord-alerter"
file_paths = ["compose.yaml"]
environment = """
  ## Required

  ## Your webhook URL
  DISCORD_WEBHOOK = [[DISCORD_WEBHOOK]]

  ## Optional

  ## Set whether to include Komodo Severity Level in notification title
  #LEVEL_IN_TITLE=true

  # Prefixes messages with a checkmark when the Alert is in the 'Resolved' state
  #INDICATE_RESOLVED=true

  # Filter if an alert is pushed based on its Resolved status
  # * leave unset to push all alerts
  # * otherwise, alerts will only be pushed if Alert is one of the comma-separated states set here
  #ALLOW_RESOLVED_TYPE=resolved,unresolved

  ## Delay alerts with below types for X milliseconds 
  ## and cancel pushing alert if it is resolved within that time
  #UNRESOLVED_TIMEOUT_TYPES=ServerCpu,ServerMem
  #UNRESOLVED_TIMEOUT=2000
"""

##

[[stack]]
name = "dockerproxy-26"
tags = ["komodo-2"]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  dockerproxy-26:
    image: lscr.io/linuxserver/socket-proxy:latest
    container_name: dockerproxy-26
    networks:
      - d3internal
    privileged: yes
    environment:
      - ALLOW_START=0 #optional
      - ALLOW_STOP=0 #optional
      - ALLOW_RESTARTS=0 #optional
      - AUTH=0 #optional
      - BUILD=0 #optional
      - COMMIT=0 #optional
      - CONFIGS=0 #optional
      - CONTAINERS=0 #optional
      - DISABLE_IPV6=0 #optional
      - DISTRIBUTION=0 #optional
      - EVENTS=1 #optional
      - EXEC=0 #optional
      - IMAGES=0 #optional
      - INFO=0 #optional
      - LOG_LEVEL=info #optional
      - NETWORKS=0 #optional
      - NODES=0 #optional
      - PING=1 #optional
      - PLUGINS=0 #optional
      - POST=0 #optional
      - SECRETS=0 #optional
      - SERVICES=0 #optional
      - SESSION=0 #optional
      - SWARM=0 #optional
      - SYSTEM=0 #optional
      - TASKS=0 #optional
      - VERSION=1 #optional
      - VOLUMES=0 #optional
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    restart: unless-stopped
    read_only: true
    tmpfs:
      - /run
"""

##

[[stack]]
name = "dockerproxy-27"
tags = ["komodo-3"]
[stack.config]
server = "komodo-3"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  dockerproxy-27:
    image: lscr.io/linuxserver/socket-proxy:latest
    container_name: dockerproxy-27
    networks:
      - d3internal
    environment:
      - ALLOW_START=0 #optional
      - ALLOW_STOP=0 #optional
      - ALLOW_RESTARTS=0 #optional
      - AUTH=0 #optional
      - BUILD=0 #optional
      - COMMIT=0 #optional
      - CONFIGS=0 #optional
      - CONTAINERS=0 #optional
      - DISABLE_IPV6=0 #optional
      - DISTRIBUTION=0 #optional
      - EVENTS=1 #optional
      - EXEC=0 #optional
      - IMAGES=0 #optional
      - INFO=0 #optional
      - LOG_LEVEL=info #optional
      - NETWORKS=0 #optional
      - NODES=0 #optional
      - PING=1 #optional
      - PLUGINS=0 #optional
      - POST=0 #optional
      - SECRETS=0 #optional
      - SERVICES=0 #optional
      - SESSION=0 #optional
      - SWARM=0 #optional
      - SYSTEM=0 #optional
      - TASKS=0 #optional
      - VERSION=1 #optional
      - VOLUMES=0 #optional
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    restart: unless-stopped
    read_only: true
    tmpfs:
      - /run
"""

##

[[stack]]
name = "dozzel-agent-1"
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  dozzle-agent:
    image: amir20/dozzle:latest
    command: agent
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    ports:
      - 7007:7007
"""

##

[[stack]]
name = "dozzle"
tags = [
  "internal",
  "monitoring",
  "komodo-3",
  "docker"
]
[stack.config]
server = "komodo-28"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  dozzle:
    image: amir20/dozzle:latest
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 8787:8080
    env_file:
      - .env
    labels:
      proxy.dozzle.port: 8787
      proxy.dozzle-backend.port: 8080
"""
environment = """
DOZZLE_ENABLE_ACTIONS=true
DOZZLE_ENABLE_SHELL=true
#DOZZLE_AUTH_PROVIDER: forward-proxy
DOZZLE_REMOTE_AGENT=10.10.10.25:7007,10.10.10.26:7007
"""

##

[[stack]]
name = "dozzle-agent-2"
tags = [
  "internal",
  "monitoring",
  "komodo-2"
]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  dozzle-agent:
    image: amir20/dozzle:latest
    command: agent
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    ports:
      - 7007:7007
"""

##

[[stack]]
name = "dumbpad"
tags = ["external", "komodo-2"]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  dumbpad:
    image: dumbwareio/dumbpad:latest
    container_name: dumbpad
    restart: unless-stopped
    networks:
      - d3internal
    ports:
      - 3765:3000
    volumes:
      - ${DOCKER_DATA}/dumbpad/data:/app/data
    environment:
      # The title shown in the web interface
      SITE_TITLE: ${DUMBPAD_SITE_TITLE:-DumbPad}
      # Optional PIN protection (leave empty to disable)
      DUMBPAD_PIN: ${DUMBPAD_PIN}
      # The base URL for the application
      BASE_URL: ${DUMBPAD_BASE_URL:-http://localhost:3000} # Use ALLOWED_ORIGINS below to restrict cors to specific origins
      # (OPTIONAL)
      # Usage: Comma-separated list of urls: http://localhost:port,http://internalip:port,https://base.proxy.tld,https://authprovider.domain.tld
      # ALLOWED_ORIGINS: ${DUMBPAD_ALLOWED_ORIGINS:-http://localhost:3000} # Comment out to allow all origins (*)
      # LOCKOUT_TIME: ${DUMBPAD_LOCK_TIME:-15} # Customize pin lockout time (if empty, defaults to 15 in minutes)
      # MAX_ATTEMPTS: ${DUMBPAD_MAX_ATTEMPTS:-5} # Customize pin max attempts (if empty, defaults to 5)
      # COOKIE_MAX_AGE: ${DUMBPAD_COOKIE_MAX_AGE:-24} # Customize maximum age of cookies primarily used for pin verification (default 24) in hours
      # PAGE_HISTORY_COOKIE_AGE: ${DUMBPAD_PAGE_HISTORY_COOKIE_AGE:-365} # Customize age of cookie to show the last notepad opened (default 365 | max 400) in days - shows default notepad on load if expired
      
      # MARKDOWN CODE SYNTAX HIGHLIGHTING (only use below if you want to restrict to specific languages):
      # By default, DumbPad includes support for all ~180 languages supported by highlight.js.
      # view entire list and usage in /docs/MARKDOWN_SYNTAX_HIGHLIGHTING_USAGE.md
      # HIGHLIGHT_LANGUAGES=c,csharp,css,dockerfile,go,html,java,javascript,json,kotlin,markdown,perl,php,python,ruby,sql,swift,typescript,xml,yaml
    labels:
      - homepage.group=Tools
      - homepage.name=Dumbpad
      - homepage.icon=sh-dumbpad-light
      - homepage.href=https://dumbpad.d3adc3ii.cc/
"""
environment = """
DUMBPAD_PIN=210825
"""

##

[[stack]]
name = "dumbterm"
tags = [
  "external",
  "production",
  "komodo-2"
]
[stack.config]
server = "komodo-2"
links = ["https://dumbterm.d3adc3ii.cc"]
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal: 
    external: true
services:
  dumbterm:
    image: dumbwareio/dumbterm:latest
    container_name: dumbterm
    restart: unless-stopped
    networks:
      - d3internal
    ports:
      - ${DUMBTERM_PORT}:3000
    volumes:
      - ${DUMBTERM_CONFIG}:/root/.config
      - ${DUMBTERM_DATA_DIR}:/root/data
    environment:
      # Container timezone
      TZ: ${DUMBTERM_TZ}
      # The title shown in the web interface
      SITE_TITLE: ${DUMBTERM_SITE_TITLE:-DumbTerm}
      # Recommended PIN protection (leave empty to disable)
      DUMBTERM_PIN: ${DUMBTERM_PIN}
      # The base URL for the application
      BASE_URL: ${DUMBTERM_BASE_URL}
      ENABLE_STARSHIP: ${ENABLE_STARSHIP:-true}
      LOCKOUT_TIME: ${DUMBTERM_LOCKOUT_TIME:-15} # Minutes
      # Session duration in hours before requiring re-authentication
      MAX_SESSION_AGE: ${DUMBTERM_MAX_SESSION_AGE:-24} # Hours
      # (OPTIONAL) - List of allowed origins for CORS
      # ALLOWED_ORIGINS: ${DUMBTERM_ALLOWED_ORIGINS:-http://localhost:3000}
    labels:
      - homepage.group=Access
      - homepage.name=Dumbterm
      - homepage.icon=sh-dumbterm-light
      - homepage.href=https://dumbterm.d3adc3ii.cc
"""
environment = """
DUMBTERM_CONFIG="/mnt/zApps/dumbterm/config"
DUMBTERM_DATA_DIR="/mnt/zApps/dumbterm/data"
DUMBTERM_TZ="Asia/Singapore"
DUMBTERM_PIN=1111
DUMBTERM_PORT=3002
DUMBTERM_BASE_URL=http://dumbterm.d3adc3ii.cc:3002
"""

##

[[stack]]
name = "godoxy"
tags = [
  "internal",
  "core",
  "proxy",
  "komodo-1"
]
[stack.config]
server = "komodo-1"
links = ["https://doxy.d3adc3ii.site/"]
project_name = "godoxy"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  socket-proxy:
    container_name: socket-proxy
    image: ghcr.io/yusing/socket-proxy:latest
    networks:
      - d3internal
    environment:
      - ALLOW_START=1
      - ALLOW_STOP=1
      - ALLOW_RESTARTS=1
      - CONTAINERS=1
      - EVENTS=1
      - INFO=1
      - PING=1
      - POST=1
      - VERSION=1
    volumes:
      - ${DOCKER_SOCKET:-/var/run/docker.sock}:/var/run/docker.sock
    restart: unless-stopped
    tmpfs:
      - /run
    ports:
      - ${SOCKET_PROXY_LISTEN_ADDR:-127.0.0.1:2375}:2375
  frontend:
    image: ghcr.io/yusing/godoxy-frontend:${TAG:-latest}
    container_name: godoxy-frontend
    restart: unless-stopped
    network_mode: host
    env_file: .env
    user: 1000:1000
    read_only: true
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - all
    depends_on:
      - app
    environment:
      HOSTNAME: 127.0.0.1
      PORT: ${GODOXY_FRONTEND_PORT}
    labels:
      proxy.aliases: ${GODOXY_FRONTEND_ALIASES}
      proxy.doxy.port: ${GODOXY_FRONTEND_PORT}
     # proxy.doxy.middlewares.oidc:
      # proxy.#1.middlewares.cidr_whitelist: |
      #   status: 403
      #   message: IP not allowed
      #   allow:
      #     - 127.0.0.1
      #     - 10.0.0.0/8
      #     - 192.168.0.0/16
      #     - 172.16.0.0/12
  app:
    image: ghcr.io/yusing/godoxy:${TAG:-latest}
    container_name: godoxy-proxy
    restart: always
    network_mode: host # do not change this
    #extra_hosts:
    #  - auth.d3adc3ii.cc:127.0.0.1
    dns:
      - 1.1.1.1
      - 1.1.1.2
    environment:
      - CF_API_TOKEN= ${CF_API_TOKEN}
      - CF_EMAIL= ${CF_EMAIL}
      - DOCKER_HOST=tcp://${SOCKET_PROXY_LISTEN_ADDR:-127.0.0.1:2375}
    env_file: .env
    user: 1000:1000
    depends_on:
      socket-proxy:
        condition: service_started
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - all
    cap_add:
      - NET_BIND_SERVICE
    volumes:
      - ${DOCKER_DATA}/godoxy/config:/app/config
      - ${DOCKER_DATA}/godoxy/logs:/app/logs
      - ${DOCKER_DATA}/godoxy/error_pages:/app/error_pages:ro
      - ${DOCKER_DATA}/godoxy/data:/app/data
      - ${DOCKER_DATA}/godoxy/certs:/app/certs

      # remove "./certs:/app/certs" and uncomment below to use existing certificate
      # - /path/to/certs/cert.crt:/app/certs/cert.crt
      # - /path/to/certs/priv.key:/app/certs/priv.key
"""
environment = """
COMPOSE_PROJECT_NAME= godoxy
TAG=latest
TZ=Asia/Singapore
PUID=1000
PGID=1000
GODOXY_EMAIL= d3tech@pm.me
CONFIG_DIR=/etc/komodo/repos/diiihl-3/komodo/resources/godoxy/config
CF_API_TOKEN= [[CF_API_TOKEN]]
CF_EMAIL= d3tech@pm.me
# API JWT Configuration (common)
# generate secret with `openssl rand -base64 32`
GODOXY_API_JWT_SECRET=4m64Gth6C6VZeLHxGOQzVe3Myigx5gqHm4KqN5HxwM8=
# the JWT token time-to-live
# leave empty to use default (24 hours)
# format: https://pkg.go.dev/time#Duration
GODOXY_API_JWT_TOKEN_TTL=

# API/WebUI user password login credentials (optional)
# These fields are not required for OIDC authentication
GODOXY_API_USER=d3
GODOXY_API_PASSWORD=qyp.kmr2ktf5vcj3CYM

# OIDC Configuration (optional)
# Uncomment and configure these values to enable OIDC authentication.
#

#GODOXY_OIDC_ISSUER_URL= https://auth.d3adc3ii.cc/application/o/godoxy/                       
#GODOXY_OIDC_CLIENT_ID=LLYuk9x6gWycwkdfiAsjVQtANvtuQyqH4iVHQmMK
#GODOXY_OIDC_CLIENT_SECRET=FKnuEPQQRq5ZTu2hBhd2uTeCjWg1CT6PtjgD1d2AcBZK2L0BYomunCWhkO7vcuNdAHfD0MbZEeqiFGBTAfjjWyU3FRdgLyqh3bsoGTM7zCf7O7wdPrZW4SIQeLRLfqCm
#GODOXY_OIDC_SCOPES=openid, profile, email, groups
#GODOXY_OIDC_ALLOWED_USERS=d3
# User definitions: Uncomment and configure these values to restrict access to specific users or groups.
# These two fields act as a logical AND operator. For example, given the following membership:
#   user1, group1
#   user2, group1
#   user3, group2
#   user1, group2
# You can allow access to user3 AND all users of group1 by providing:
#   # GODOXY_OIDC_ALLOWED_USERS=user3
#GODOXY_OIDC_ALLOWED_GROUPS=	"authentik Admins"
#
# Comma-separated list of allowed users.
# GODOXY_OIDC_ALLOWED_USERS=user1,user2
# Optional: Comma-separated list of allowed groups.
# GODOXY_OIDC_ALLOWED_GROUPS=group1,group2

# Proxy listening address
GODOXY_HTTP_ADDR=:80
GODOXY_HTTPS_ADDR=:443

# Enable HTTP3
GODOXY_HTTP3_ENABLED=true

# API listening address
GODOXY_API_ADDR=127.0.0.1:8888

# Metrics
GODOXY_METRICS_DISABLE_CPU=false
GODOXY_METRICS_DISABLE_MEMORY=false
GODOXY_METRICS_DISABLE_DISK=false
GODOXY_METRICS_DISABLE_NETWORK=false
GODOXY_METRICS_DISABLE_SENSORS=false

# Frontend listening port
GODOXY_FRONTEND_PORT=3716

# Frontend aliases (subdomains / FQDNs, e.g. godoxy, godoxy.domain.com)
GODOXY_FRONTEND_ALIASES=doxy

# Docker socket
# /var/run/podman/podman.sock for podman
DOCKER_SOCKET=/var/run/docker.sock
SOCKET_PROXY_LISTEN_ADDR=127.0.0.1:2375

# Debug mode
GODOXY_DEBUG=true
"""

##

[[stack]]
name = "healthcheck"
tags = [
  "internal",
  "monitoring",
  "komodo-1"
]
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
#networks:
#  caddy:
#    external: true

services:
  healthchecks:
    image: lscr.io/linuxserver/healthchecks:latest
    container_name: healthchecks
    #networks:
    #  - caddy
    env_file:
      - .env
    #environment:
      #- CSRF_TRUSTED_ORIGINS= #optional
      #- DEBUG=True #optional
      #- DEFAULT_FROM_EMAIL= #optional
      #- EMAIL_HOST= #optional
      #- EMAIL_PORT= #optional
      #- EMAIL_HOST_USER= #optional
      #- EMAIL_HOST_PASSWORD= #optional
      #- EMAIL_USE_TLS= #optional
      #- INTEGRATIONS_ALLOW_PRIVATE_IPS= #optional
      #- PING_EMAIL_DOMAIN= #optional
      #- RP_ID= #optional
      #- SITE_LOGO_URL= #optional
    volumes:
      - ${DATA_DIR}/config:/config
    ports:
      - 8898:8000
      - 2525:2525 #optional
    restart: unless-stopped
    labels:
       proxy.idle_timeout: 1h
       proxy.port: 8898
"""
environment = """
PUID=1000
PGID=1000
DATA_DIR=/mnt/zApps/healthcheck
SITE_ROOT= "https://health.d3adc3ii.site"
ALLOWED_HOSTS=health.d3adc3ii.site
SITE_NAME= Healthcheck
SUPERUSER_EMAIL= d3tech@pm.me
SUPERUSER_PASSWORD= [[HEALTHCHECK_SUPERADMIN_PASSWORD]]
SECRET_KEY= [[HEALTHCHECK_SECRET]]
APPRISE_ENABLED=True
TZ=Asia/Singapore
"""

##

[[stack]]
name = "homepage"
tags = [
  "external",
  "production",
  "komodo-1"
]
[stack.config]
server = "komodo-1"
links = ["https://homepage.d3adc3ii.cc"]
project_name = "homepage"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  homepage:
    image: ghcr.io/gethomepage/homepage:latest
    container_name: homepage
    networks:
      - d3internal
    env_file:
      - .env
    ports:
      - 3731:3000
    volumes:
      - ${HOMEPAGE_DATA_DIR}/homepage/config:/app/config 
      - ${HOMEPAGE_DATA_DIR}/homepage/icons:/app/public/icons
      - ${HOMEPAGE_DATA_DIR}/homepage/images:/app/public/images
      #- /var/run/docker.sock:/var/run/docker.sock:ro
    restart: unless-stopped
  #dockerproxy:
    #image: ghcr.io/tecnativa/docker-socket-proxy:latest
    #container_name: dockerproxy
    #networks:
      #- d3internal
    #environment:
     # - CONTAINERS=1 # Allow access to viewing containers
      #- SERVICES=1 # Allow access to viewing services (necessary when using Docker Swarm)
      #- TASKS=1 # Allow access to viewing tasks (necessary when using Docker Swarm)
      #- POST=0 # Disallow any POST operations (effectively read-only)
    #ports:
    #  - "2375:2375"
    #volumes:
      #- /var/run/docker.sock:/var/run/docker.sock:ro # Mounted as read-only
    #restart: unless-stopped
"""
environment = """
HOMEPAGE_DATA_DIR= /etc/komodo/repos/diiihl/komodo/resources/
HOMEPAGE_ALLOWED_HOSTS= "homepage.d3adc3ii.cc,homepage.d3adc3ii.site,10.10.10.25:3000"
PGID= [[PGID]] 
PUID= [[PUID]] 
# Site Config
HOMEPAGE_VAR_TITLE= "d3 Homepage"
HOMEPAGE_VAR_FAVICON= "/icons/d3logo.png"
HOMEPAGE_VAR_IMG_URL= "/images/hack.jpg"
HOMEPAGE_VAR_HEADER_STYLE= boxed #boxedWidgets

HOMEPAGE_VAR_IMG_BLUR= md
HOMEPAGE_VAR_IMG_SATURATE= 50
HOMEPAGE_VAR_IMG_BRIGHTNESS= 50
HOMEPAGE_VAR_IMG_OPACITY=70
HOMEPAGE_VAR_USE_EQUAL_HEIGHTS= true
HOMEAGE_VAR_DISABLE_COLLAPSE= true


### GLANCES WIDGET SETTINGS
HOMEPAGE_VAR_GL11_URL= http://10.10.10.11:61208
HOMEPAGE_VAR_GL11_VERSION= 4 # required only if running glances v4 or higher, defaults to 3
HOMEPAGE_VAR_GL11_CPU= false # optional, enabled by default, disable by setting to false
HOMEPAGE_VAR_GL11_MEM= false # optional, enabled by default, disable by setting to false
HOMEPAGE_VAR_GL11_CPUTEMP= true # disabled by default
HOMEPAGE_VAR_GL11_UPTIME= true # disabled by default
HOMEPAGE_VAR_GL11_LABEL= pve11 # optional

HOMEPAGE_VAR_GL12_URL= http://10.10.10.12:61208
HOMEPAGE_VAR_GL12_VERSION= 4 
HOMEPAGE_VAR_GL12_CPU= false 
HOMEPAGE_VAR_GL12_MEM= false 
HOMEPAGE_VAR_GL12_CPUTEMP= true 
HOMEPAGE_VAR_GL12_UPTIME= true 
HOMEPAGE_VAR_GL12_LABEL= pve12 

HOMEPAGE_VAR_GL13_URL= http://10.10.10.13:61208
HOMEPAGE_VAR_GL13_VERSION= 4
HOMEPAGE_VAR_GL13_CPU= false 
HOMEPAGE_VAR_GL13_MEM= false 
HOMEPAGE_VAR_GL13_CPUTEMP= true 
HOMEPAGE_VAR_GL13_UPTIME= true 
HOMEPAGE_VAR_GL13_LABEL= pve13 

#### INFRA ####################################################################################################################################################################################################
# Proxmox
HOMEPAGE_VAR_PROXMOX_ICON= "/icons/proxmox-light.png"
HOMEPAGE_VAR_PROXMOX_URL_PVE11= "https://pve.d3adc3ii.site"
HOMEPAGE_VAR_PROXMOX_IP_PVE11="https://10.10.10.11:8006"
#HOMEPAGE_VAR_PROXMOX_USER=homepage@pve!homepage 
HOMEPAGE_VAR_PROXMOX_SECRET=dde7d522-1e7f-4a5f-a9cf-081b351a3a1f
HOMEPAGE_VAR_PBS_URL= "https://pbs.d3adc3ii.site"
# Truenas
HOMEPAGE_VAR_TRUENAS_ICON= "/icons/truenas-scale-light.png"
HOMEPAGE_VAR_TRUENAS_URL= "https://truenas.d3adc3ii.site"
HOMEPAGE_VAR_TRUENAS_KEY="1-zM5Mm8l4VdRa4WNybTWjVdHVM89TR7fkGj40DkYEPgFdkt83DYBea95J3SHe3uCe"
HOMEPAGE_VAR_TRUENAS_ENABLEDPOOL= true
# Komodo
HOMEPAGE_VAR_KOMODO_ICON= "/icons/docker-light.png"
HOMEPAGE_VAR_KOMODO_URL= "https://komodo.d3adc3ii.cc"
HOMEPAGE_VAR_KOMODO_IPURL= "http://10.10.10.25:9120"
HOMEPAGE_VAR_KOMODO_KEY=K-69zvNUYoxn5KREW5nVpLqeLa741U7NHmPXoEx4S1
HOMEPAGE_VAR_KOMODO_SECRET=S-5hhHrLWPfLHPJCRGBMV2auU7QsqfUaGrTJYuOW9M

#### DOMAIN ####################################################################################################################################################################################################
# Authentik
HOMEPAGE_VAR_AUTHENTIK_ICON= "/icons/authentik-light.png"
HOMEPAGE_VAR_AUTHENTIK_URL= "https://auth.d3adc3ii.cc"
HOMEPAGE_VAR_AUTHENTIK_KEY= "ZnhLrOvUoWZfHcQpFrteQVekOjpGQh48lXEVFn34HvGtT8eJoyhgaNYWb2mI"
# DNS
HOMEPAGE_VAR_DNS_ICON= "/icons/technitium-light.png"
HOMEPAGE_VAR_DNS_URL= "https://ns.d3adc3ii.site"
HOMEPAGE_VAR_DNS_KEY="4646abc150fb4277522a160965f64444d12d6417d32e594a73472e63e20c7ac1"
HOMEPAGE_VAR_DNS_RANGE: LastDay # optional, defaults to LastHour
# GoDoxy
HOMEPAGE_VAR_GODOXY_ICON= "/icons/godoxy-light.png"
HOMEPAGE_VAR_GODOXY_URL= "https://doxy.d3adc3ii.site"
# PANGOLIN
HOMEPAGE_VAR_PANGOLIN_ICON= "/icons/pangolin-light.png"
HOMEPAGE_VAR_PANGOLIN_URL= "https://pangolin.d3adc3ii.cc"

#### NETWORK ####################################################################################################################################################################################################
# NetAlertX 
HOMEPAGE_VAR_NETALERTX_ICON= "/icons/netalertx-light.png"
HOMEPAGE_VAR_NETALERTX_URL= "https://netalertx.d3adc3ii.site"
HOMEPAGE_VAR_NETALERTX_KEY="t_pJ26L2qEeUcR6bz5RCGI"
HOMEPAGE_VAR_NETALERTX_FIELDS= ["connected","down_alerts","new_devices"] 
# UPTIME KUMA
HOMEPAGE_VAR_KUMA_ICON= "/icons/uptime-kuma-light.png"
HOMEPAGE_VAR_KUMA_URL= "https://uptime.d3adc3ii.cc"
HOMEPAGE_VAR_KUMA_KEY=uk1_CJtVJXDT8DFll97KXiPPXb6dEWHpOdBZXymKWLPn
# PHPIPAM
HOMEPAGE_VAR_PHPIPAM_URL= "https://phpipam.d3adc3ii.cc/"
HOMEPAGE_VAR_PHPIPAM_ICON= "sh-phpmyadmin-light"
# Nautobot
HOMEPAGE_VAR_NAUTOBOT_URL= "https://nautobot.d3adc3ii.cc/"
HOMEPAGE_VAR_NAUTOBOT_ICON= "/icons/netbox-light.png"
# NETBOX CLOUD
HOMEPAGE_VAR_NETBOX_ICON= "/icons/netbox-light.png"
HOMEPAGE_VAR_NETBOXCL_URL= "https://wmfk3018.cloud.netboxapp.com"
# NETBOX CONSOLE
HOMEPAGE_VAR_NETBOXCS_URL= "https://console.netboxlabs.com/"# NETBOX CONSOLE
HOMEPAGE_VAR_NETBOXCS_URL= "https://console.netboxlabs.com/"

#### MONITORING  ####################################################################################################################################################################################################
# Beszel
HOMEPAGE_VAR_BESZEL_ICON= "/icons/beszel-light.png"
HOMEPAGE_VAR_BESZEL_URL= "https://beszel.d3adc3ii.cc"
HOMEPAGE_VAR_BESZEL_USERNAME= "d3tech@pm.me"
HOMEPAGE_VAR_BESZEL_PASSWORD= "KVG6qpu0rnb-ybd9etn" 
HOMEPAGE_VAR_BESZEL_VERSION= "2"
HOMEPAGE_VAR_BESZEL_SYSTEMID_pve11= pve11
HOMEPAGE_VAR_BESZEL_SYSTEMID_pve12= pve12
HOMEPAGE_VAR_BESZEL_SYSTEMID_pve13= pve13
HOMEPAGE_VAR_BESZEL_SYSTEMID_pbs= pbs
HOMEPAGE_VAR_BESZEL_FIELDS= ["cpu","memory","disk","network"]
# SPEEDTEST
HOMEPAGE_VAR_SPEEDTEST_ICON= "sh-speedtest-tracker-light"
HOMEPAGE_VAR_SPEEDTEST_URL= "https://speedtest.d3adc3ii.site"
# Wazuh
HOMEPAGE_VAR_WAZUH_ICON= "/icons/wazuh-light.png"
HOMEPAGE_VAR_WAZUH_URL= "https://wazuh.d3adc3ii.site"
# APPRISE-API
HOMEPAGE_VAR_APPRISE_ICON= "/icons/gotify-dark.png"
HOMEPAGE_VAR_APPRISE_URL= "http://192.168.2.33:8000"
# Healthchecks
HOMEPAGE_VAR_HEALTHCHECKS_ICON= "/icons/healthchecks-light.png"
HOMEPAGE_VAR_HEALTHCHECKS_URL= "http://health.d3adc3ii.site"
# Smokeping
HOMEPAGE_VAR_SMOKEPING_ICON= "/icons/smokeping.png"
HOMEPAGE_VAR_SMOKEPING_URL= "http://192.168.2.21/smokeping"

#### BACKUP ####################################################################################################################################################################################################
# PBS
HOMEPAGE_VAR_PBS_USER=homepage@pbs!homepage
HOMEPAGE_VAR_PBS_SECRET=56ff3a13-0620-432b-b173-d048b1298a50
# Backrest
HOMEPAGE_VAR_BACKREST_ICON= "/icons/backrest-light.png"
HOMEPAGE_VAR_BACKREST_URL= "https://backrest.d3adc3ii.site"

# Remote-Backups
HOMEPAGE_VAR_REMOTEBACKUP_ICON= "/icons/proxmox-light.png"
HOMEPAGE_VAR_REMOTEBACKUP_URL= "https://dashboard.remote-backups.com"


#### MEDIA ####################################################################################################################################################################################################
# Jellyfin
HOMEPAGE_VAR_JELLY_ICON= "/icons/jellyfin-light.png"
HOMEPAGE_VAR_JELLY_URL= "https://jelly.d3adc3ii.site"
HOMEAGE_VAR_JELLY_WIDGETURL= "http://10.10.10.27:8096"
HOMEPAGE_VAR_JELLY_KEY=a6a45c61dd1d4f059b02fa22ad8c0ef3
HOMEPAGE_VAR_JELLY_ENABLEBLOCK=true
HOMEPAGE_VAR_JELLY_NOWPLAY=false

# Immich
HOMEPAGE_VAR_IMMICH_ICON = "/icons/immich-light.png"
HOMEPAGE_VAR_IMMICH_URL= "https://immich.d3adc3ii.site"
HOMEPAGE_VAR_IMMICH_KEY=W7IJnjVEIhc7d72AAm4sxJ49YJI1kdtkiVvmCZipVqc
HOMEPAGE_VAR_IMMICH_VERSION= 2
HOMEPAGE_VAR_IMMICH_FIELDS= ["storage","photos","videos"] 
# Stash
HOMEPAGE_VAR_STASH_ICON= "/icons/stash-light.png"
HOMEPAGE_VAR_STASH_URL= "https://stash.d3adc3ii.site"
HOMEPAGE_VAR_STASH_USER= "d3adc3ii"
HOMEPAGE_VAR_QBIT_API= "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1aWQiOiJkMyIsInN1YiI6IkFQSUtleSIsImlhdCI6MTc0NjAzOTExOX0.OQqokQMNgdCRNxfPOQGOTFH4GCB0pQvZbIS9orkgkrg"

#### ACCESS ####################################################################################################################################################################################################
# Guacamole
HOMEPAGE_VAR_GUACAMOLE_ICON= "/icons/apache-guacamole-light.png"
HOMEPAGE_VAR_GUACAMOLE_URL= "https://guaca.d3adc3ii.site/guacamole"
HOMEPAGE_VAR_GUACAMOLEEXT_URL= "https://guaca.d3adc3ii.cc/guacamole"
# SHELLHUB
HOMEPAGE_VAR_SHELLHUB_ICON= "sh-shellhub-light"
HOMEPAGE_VAR_SHELLHUB_URL= "http://192.168.2.33"

#### LOGGING ####################################################################################################################################################################################################
# Grafana
HOMEPAGE_VAR_GRAFANA_ICON= "/icons/grafana-light.png"
HOMEPAGE_VAR_GRAFANA_URL= "https://d3adc3ii.grafana.net/dashboards"
HOMEPAGE_VAR_GRAFANAPANGOLIN_URL= "https://grafana.d3adc3ii.cc/d/n5bu_kv45/traefik-official-standalone-dashboard"
# Scutiny
HOMEPAGE_VAR_SCRUTINY_ICON= "/icons/scrutiny-light.png"
HOMEPAGE_VAR_SCRUTINY_URL= "https://scrutiny.d3adc3ii.cc" 
# ZABBIX
HOMEPAGE_VAR_ZABBIX_ICON= "/icons/zabbix-light.png"
HOMEPAGE_VAR_ZABBIX_URL= "https://zabbix.d3adc3ii.cc/zabbix"
# Checkmk
HOMEPAGE_VAR_CHECKMK_ICON= "/icons/checkmk-light.png"
HOMEPAGE_VAR_CHECKMK_URL= "https://checkmk.d3adc3ii.cc/d3/check_mk"
# Dozzle
HOMEPAGE_VAR_DOZZLE_ICON= "sh-dozzle-light"
HOMEPAGE_VAR_DOZZLE_URL= "https://dozzle.d3adc3ii.site"
# Pulse
HOMEPAGE_VAR_PULSEXT_ICON= "sh-proxmox-light"
HOMEPAGE_VAR_PULSEXT_URL= "https://pulse.d3adc3ii.cc"

#### APPS ####################################################################################################################################################################################################
# Actual Budget
HOMEPAGE_VAR_ACTUAL_ICON= "sh-actual-budget-light"
HOMEPAGE_VAR_ACTUAL_URL= "https://actual.d3adc3ii.site"
# Sensei
HOMEPAGE_VAR_SENSEI_ICON= "sh-sentry-light"
HOMEPAGE_VAR_SENSEI_URL= "https://statement.d3adc3ii.site"
# Semaphore
HOMEPAGE_VAR_SEMAPHORE_ICON= "/icons/semaphore-ui-light.png"
HOMEPAGE_VAR_SEMAPHORE_URL= "https://semaphore.d3adc3ii.site"
# Aria2
HOMEPAGE_VAR_ARIA_ICON= "sh-aria2-light"
HOMEPAGE_VAR_ARIA_URL= "https://dl.d3adc3ii.site"
# NZBGET
HOMEPAGE_VAR_NZBGET_ICON= "sh-nzbget-light"
HOMEPAGE_VAR_NZBGET_URL= "https://nzbget.d3adc3ii.site"
# Karakeep
HOMEPAGE_VAR_KARAKEEP_ICON= "/icons/karakeep.png"
HOMEPAGE_VAR_KARAKEEP_URL= "https://kara.d3adc3ii.cc"
# Wallos
HOMEPAGE_VAR_WALLOS_ICON= "/icons/wallos-light.png"
HOMEPAGE_VAR_WALLOS_URL= "https://wallos.d3adc3ii.cc"
# Ommni Tools
HOMEPAGE_VAR_OMNITOOLS_ICON= "sh-omnitools-light"
HOMEPAGE_VAR_OMNITOOLS_URL= "https://omnitools.d3adc3ii.cc"

#### TOOLS ####################################################################################################################################################################################################

#### EXTRAS ####################################################################################################################################################################################################
# Selfhst-icons
HOMEPAGE_VAR_SELFHST_ICON= "sh-selfh-st-light" 
HOMEPAGE_VAR_SELFHST_URL= "https://selfhst-icons.d3adc3ii.cc"

###################   CORP    ##################### 

# Komodo
HOMEPAGE_VAR_KOMODOCORP_URL="http://10.203.1.121:9120"
# Fenrus
HOMEPAGE_VAR_FENRUS_ICON="sh-fenrus"
HOMEPAGE_VAR_FENRUS_URL="http://10.203.1.120:3222"
# PVECORP
HOMEPAGE_VAR_PVECORP_URL="https://10.203.1.113:8006"

### GL1 ###
# PVE11
HOMEPAGE_VAR_PVE11_URL= "https://pve11.d3adc3ii.cc"
HOMEPAGE_VAR_PVE12_URL= "10.10.10.12"
HOMEPAGE_VAR_PVE13_URL= "10.10.10.13"
HOMEPAGE_VAR_GLANCES_PVE11= "http://10.10.10.11:61208"
HOMEPAGE_VAR_GLANCES_PVE12= "http://10.10.10.12:61208"
HOMEPAGE_VAR_GLANCES_PVE13= "http://10.10.10.13:61208"
"""

##

[[stack]]
name = "immich"
tags = [
  "komodo-28",
  "production",
  "internal"
]
[stack.config]
server = "komodo-28"
file_contents = """
#
# WARNING: To install Immich, follow our guide: https://immich.app/docs/install/docker-compose
#
# Make sure to use the docker-compose.yml of the current release:
#
# https://github.com/immich-app/immich/releases/latest/download/docker-compose.yml
#
# The compose file on main may not be compatible with the latest release.

name: immich

services:
  immich-server:
    container_name: immich
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    # extends:
    #   file: hwaccel.transcoding.yml
    #   service: cpu # set to one of [nvenc, quicksync, rkmpp, vaapi, vaapi-wsl] for accelerated transcoding
    environment:
      - PGID=1000
      - PUID=1000
    volumes:
      # Do not edit the next line. If you want to change the media storage location on your system, edit the value of UPLOAD_LOCATION in the .env file
      - ${UPLOAD_LOCATION}:/usr/src/app/upload
      - ${DOCKER_DATA}/immich-upload:/mnt/upload
      - /etc/localtime:/etc/localtime:ro
    env_file:
      - .env
    ports:
      - '2283:2283'
    depends_on:
      - redis
      - database
    restart: always
    healthcheck:
      disable: false

  immich-machine-learning:
    container_name: immich_machine_learning
    # For hardware acceleration, add one of -[armnn, cuda, rocm, openvino, rknn] to the image tag.
    # Example tag: ${IMMICH_VERSION:-release}-cuda
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}
    # extends: # uncomment this section for hardware acceleration - see https://immich.app/docs/features/ml-hardware-acceleration
    #   file: hwaccel.ml.yml
    #   service: cpu # set to one of [armnn, cuda, rocm, openvino, openvino-wsl, rknn] for accelerated inference - use the `-wsl` version for WSL2 where applicable
    volumes:
      - model-cache:/cache
    env_file:
      - .env
    restart: always
    healthcheck:
      disable: false

  redis:
    container_name: immich_redis
    image: docker.io/valkey/valkey:8-bookworm@sha256:facc1d2c3462975c34e10fccb167bfa92b0e0dbd992fc282c29a61c3243afb11
    healthcheck:
      test: redis-cli ping || exit 1
    restart: always

  database:
    container_name: immich_postgres
    image: ghcr.io/immich-app/postgres:14-vectorchord0.4.3-pgvectors0.2.0@sha256:5f6a838e4e44c8e0e019d0ebfe3ee8952b69afc2809b2c25f7b0119641978e91
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_DATABASE_NAME}
      POSTGRES_INITDB_ARGS: '--data-checksums'
      # Uncomment the DB_STORAGE_TYPE: 'HDD' var if your database isn't stored on SSDs
      # DB_STORAGE_TYPE: 'HDD'
    volumes:
      # Do not edit the next line. If you want to change the database storage location on your system, edit the value of DB_DATA_LOCATION in the .env file
      - ${DB_DATA_LOCATION}:/var/lib/postgresql/data
    shm_size: 128mb
    restart: always

volumes:
  model-cache:
"""
environment = """
IMMICH_IGNORE_MOUNT_CHECK_ERRORS=true
PGID=1000
PUID=1000
UPLOAD_LOCATION=/mnt/zApps/immich-new/upload
DB_DATA_LOCATION=./postgres
IMMICH_VERSION=release
DB_PASSWORD=[[IMMICH_DB_PASSWORD]]
POSTGRES_PASSWORD=[[IMMICH_DB_PASSWORD]]
DB_USERNAME: postgres
DB_DATABASE_NAME=immich
"""

##

[[stack]]
name = "jellyfin"
tags = [
  "internal",
  "production",
  "komodo-3"
]
[stack.config]
server = "komodo-3"
project_name = "jellyfin"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  jellyfin:
    image: lscr.io/linuxserver/jellyfin:latest
    container_name: jelly
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Singapore
      - JELLYFIN_PublishedServerUrl=https://jelly.d3adc3ii.site #optional
    volumes:
      - ${DOCKER_DATA}/jellyfin/config:/config
      - ${JELLYFIN_DATA_DIR}/tvshows:/data/tvshows
      - ${JELLYFIN_DATA_DIR}/movies:/data/movies
    ports:
      - 8096:8096
      - 8920:8920 #optional
      - 7359:7359/udp #optional
      - 1900:1900/udp #optional
    restart: unless-stopped
    labels:
      proxy.jelly.port: 8096
"""
environment = """
JELLYFIN_DATA_DIR=/mnt/zFiles/media

"""

##

[[stack]]
name = "karakeep"
tags = [
  "external",
  "production",
  "komodo-2"
]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  web:
    image: ghcr.io/karakeep-app/karakeep:${KARAKEEP_VERSION:-release}
    restart: unless-stopped
    volumes:
      - ${DOCKER_DATA}/karakeep/data:/data
    networks:
      - default
      - d3internal
    ports:
      - 3333:3000
    env_file:
      - .env
    environment:
      MEILI_ADDR: http://meilisearch:7700
      BROWSER_WEB_URL: http://chrome:9222
      DATA_DIR: /data
    labels:
      - homepage.group=Applications
      - homepage.name=Karakeep
      - homepage.icon=sh-karakeep-light
      - homepage.href=https://kara.d3adc3ii.cc/
  chrome:
    image: gcr.io/zenika-hub/alpine-chrome:123
    restart: unless-stopped
    command:
      - --no-sandbox
      - --disable-gpu
      - --disable-dev-shm-usage
      - --remote-debugging-address=0.0.0.0
      - --remote-debugging-port=9222
      - --hide-scrollbars
  meilisearch:
    image: getmeili/meilisearch:v1.13.3
    restart: unless-stopped
    env_file:
      - .env
    environment:
      MEILI_NO_ANALYTICS: "true"
    volumes:
      - meilisearch:/meili_data

volumes:
  meilisearch:
  data:
"""
environment = """
KARAKEEP_VERSION=release
NEXTAUTH_SECRET=[[KARA_NEXTAUTH_SECRET]]
MEILI_MASTER_KEY=[[KARA_MEILI_MASTER_KEY]]
NEXTAUTH_URL='https://kara.d3adc3ii.cc'
OPENAI_API_KEY=[[OPENAI_API_KEY]]
OAUTH_ALLOW_DANGEROUS_EMAIL_ACCOUNT_LINKING= true
OAUTH_WELLKNOWN_URL='https://auth.d3adc3ii.cc/application/o/karakeep/'
OAUTH_CLIENT_SECRET=db64i7QZ2MHMVkjOvZfcOyWTh1y1ECG2XNamIkLXBZxi0UqLfcfvVxYcsQ7nWbZvFeRQBGnJB2vnVqGQgKkUopKGlGooRuGW2R8DnvxoORYAVWhW77x5PVhwlOB0Cr9s
OAUTH_CLIENT_ID=D8rw3kVA932oWoPiLud8z5FgomI3sXT4oOTYMBIr
OAUTH_PROVIDER_NAME= authentik
"""

##

[[stack]]
name = "loggifly"
tags = ["internal", "monitoring"]
[stack.config]


##

[[stack]]
name = "lunalytics"
tags = [
  "komodo-3",
  "internal",
  "monitoring"
]
[stack.config]
server = "komodo-3"
links = [
  "https://lunalytics.d3adc3ii.site"
]
project_name = "lunalytics"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
# docker-compose.yml
services:
  lunalytics:
    image: ksjaay/lunalytics:latest
    container_name: lunalytics
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - '2308:2308'
    volumes:
      - ${DOCKER_DATA}/lunalytics/data:/app/data
      - ${DOCKER_DATA}/lunalytics/logs:/app/logs
    labels:
      - homepage.group=Monitor
      - homepage.name=Lunalytics
      - homepage.icon=sh-lunalytics-light
      - homepage.href=https://lunalytics.d3adc3ii.site
"""
environment = """
PGUI=1000
PUID=1000
"""

##

[[stack]]
name = "mailrise"
tags = ["komodo-3"]
[stack.config]
server = "komodo-3"
file_contents = """
services:
  mailrise:
    image: yoryan/mailrise:latest
    container_name: mailrise
    ports:
      - '8025:8025'
    restart: unless-stopped
    volumes:
      -  /mnt/zApps/mailrise/mailrise.conf:/etc/mailrise.conf:ro
"""
environment = """

"""

##

[[stack]]
name = "mktxp-stack"
[stack.config]
server = "komodo-3"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
files_on_host = true
run_directory = "/etc/komodo/stacks/mktxp-stack"
file_paths = [
  "docker-compose-mktxp-stack.yml"
]

##

[[stack]]
name = "myspeed"
tags = ["komodo-1"]
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  myspeed:
    image: germannewsmaker/myspeed
    container_name: myspeed
    networks:
      - default
      - d3internal
    ports:
      - 5216:5216
    volumes:
      - ${DOCKER_DATA}/myspeed/data:/data
    restart: unless-stopped
    labels:
      - proxy.network: default
      - homepage.group=Monitor
      - homepage.name=Myspeed
      - homepage.icon=myspeed.png
      - homepage.href=https://myspeed.d3adc3ii.site/
"""

##

[[stack]]
name = "netalertx"
tags = [
  "internal",
  "monitoring",
  "komodo-1"
]
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  netalertx:
    container_name: netalertx
    image: "ghcr.io/jokob-sk/netalertx:latest"      
    network_mode: "host"     
    restart: unless-stopped
    volumes:
      - ${DATA_DIR}/config:/app/config
      - ${DATA_DIR}/db:/app/db      
      - ${DATA_DIR}/logs:/app/log
      - type: tmpfs
        target: /app/api
    env_file:
      - .env
    labels:
      proxy.port: 20184
    dns:           
      - 10.10.10.16
"""
environment = """
DATA_DIR=/mnt/zApps/netalertx
PUID=1000
PGID=1000
TZ=Asia/Singapore
PORT=20184
"""

##

[[stack]]
name = "newt-orange"
tags = ["komodo-1"]
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  newt:
    image: fosrl/newt
    container_name: newt
    restart: unless-stopped
    environment:
      - PANGOLIN_ENDPOINT=https://pangolin.d3adc3ii.cc
      - NEWT_ID=ectuq5jqe3v33dm
      - NEWT_SECRET=1q1omrd5fi4qdf6pll1ag6swbnabxmsyn0n47tf2d1rpr9n9
      - DOCKER_SOCKET=/var/run/docker.sock
"""
environment = """
DOCKER_SOCKET=/var/run/docker.sock
"""

##

[[stack]]
name = "ns0"
tags = ["internal", "dns", "komodo-28"]
[stack.config]
server = "komodo-28"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  ns0:
    image: "technitium/dns-server:latest"
    container_name: ns0
    privileged: true
    restart: always
    environment:
      - PUID=1000
      - PGID=1000
      - DNS_SERVER_LOG_USING_LOCAL_TIME=true
      - DNS_SERVER_DOMAIN=ns2.d3adc3ii.site
    network_mode: "host"
    ports:
      - "5380:5380/tcp"
    volumes:
      - ${DOCKER_DATA}/technitium-27:/etc/dns
  keepalived:
    image: shawly/keepalived:latest
    restart: always
    environment:
      TZ: Asia/Singapore
      KEEPALIVED_VIRTUAL_IP: ${VIRTUAL_IP}
      KEEPALIVED_VIRTUAL_MASK: 24
      KEEPALIVED_CHECK_IP: ${CHECK_IP}
      KEEPALIVED_CHECK_PORT: ${CHECK_PORT}
      KEEPALIVED_VRID: 150
      KEEPALIVED_INTERFACE: eth0
      KEEPALIVED_PRIORITY: 255
      KEEPALIVED_STATE: MASTER
    network_mode: host
    cap_add:
      - NET_ADMIN
      - NET_BROADCAST
"""
environment = """
# change to an unused IP in your LAN subnet -- will be the same value on both stacks
VIRTUAL_IP=10.10.10.16
# Host IP of the other machine
CHECK_IP=10.10.10.25
CHECK_PORT=53
"""

##

[[stack]]
name = "ns1"
tags = ["internal", "komodo-1", "dns"]
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  ns1:
    image: "technitium/dns-server:latest"
    container_name: ns1
    privileged: true
    restart: always
    environment:
      - DNS_SERVER_LOG_USING_LOCAL_TIME=true
    network_mode: "host"
    ports:
      - "5380:5380/tcp"
    #  - "53:53/udp" #DNS service
    #  - "53:53/tcp" #DNS service
      # - "853:853/udp" #DNS-over-QUIC service
    #  - "853:853/tcp" #DNS-over-TLS service
      # - "443:443/udp" #DNS-over-HTTPS service (HTTP/3)
      # - "443:443/tcp" #DNS-over-HTTPS service (HTTP/1.1, HTTP/2)
    #  - "80:80/tcp" #DNS-over-HTTP service (use with reverse proxy or certbot certificate renewal)
    #  - "8053:8053/tcp" #DNS-over-HTTP service (use with reverse proxy)
      # - "67:67/udp" #DHCP service
    volumes:
      - ./technitium:/etc/dns
  keepalived:
    image: shawly/keepalived:latest
    restart: always
    environment:
      TZ: Asia/Singapore
      KEEPALIVED_VIRTUAL_IP: ${VIRTUAL_IP}
      KEEPALIVED_VIRTUAL_MASK: 24
      KEEPALIVED_CHECK_IP: ${CHECK_IP}
      KEEPALIVED_CHECK_PORT: ${CHECK_PORT}
      KEEPALIVED_VRID: 150
      # change to primary LAN interface used by the host
      KEEPALIVED_INTERFACE: eth0
      KEEPALIVED_PRIORITY: 100
      KEEPALIVED_STATE: BACKUP
    network_mode: host
    cap_add:
      - NET_ADMIN
      - NET_BROADCAST
"""
environment = """
# change to an unused IP in your LAN subnet -- will be the same value on both stacks
VIRTUAL_IP=10.10.10.16
# Host IP of the other machine
CHECK_IP=10.10.10.28
CHECK_PORT=53
"""

##

[[stack]]
name = "ntfy"
tags = [
  "internal",
  "monitoring",
  "komodo-2"
]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  ntfy:
    image: binwiederhier/ntfy
    container_name: ntfy
    command:
      - serve
    environment:
      - TZ=Asia/Singapore    # optional: set desired timezone
    user: 1000:1000 # optional: replace with your own user/group or uid/gid
    env_file:
      - .env
    volumes:
      - /var/cache/ntfy:/var/cache/ntfy
      - ${NTFY_DATA_DIR}:/etc/ntfy
    ports:
      - 8193:80
    healthcheck: # optional: remember to adapt the host:port to your environment
        test: ["CMD-SHELL", "wget -q --tries=1 http://localhost:80/v1/health -O - | grep -Eo '\"healthy\"\\s*:\\s*true' || exit 1"]
        interval: 60s
        timeout: 10s
        retries: 3
        start_period: 40s
    restart: unless-stopped
"""
environment = """
NTFY_DATA_DIR=/mnt/zApps/ntfy
"""

##

[[stack]]
name = "nzbget"
tags = ["internal", "komodo-3"]
[stack.config]
server = "komodo-28"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  nzbget:
    image: lscr.io/linuxserver/nzbget:latest
    container_name: nzbget
    env_file:
      - .env
    volumes:
      - ${DOCKER_DATA}/nzb/config:/config
      - ${DOCKER_DATA}/nzb/downloads:/downloads #optional
    ports:
      - 6789:6789
    restart: unless-stopped
    labels:
      proxy.idle_timeout: 10m
"""
environment = """
NZBGET_USER= [[NZBGET_USER]]
NZBGET_PASS= [[NZBGET_PASS]]
PUID= [[PUID]]
PGID= [[PGID]]
TZ= [[TZ]]
"""

##

[[stack]]
name = "pangolin"
tags = ["external"]
[stack.config]
server = "pangolin"
links = ["https://pangolin.d3adc3ii.cc"]
poll_for_updates = true
auto_update = true
auto_update_all_services = true
files_on_host = true
run_directory = "/home/d3"
file_paths = ["docker-compose.yml"]
environment = """
CLOUDFLARE_DNS_API_TOKEN= [[CF_API_TOKEN_PANGOLIN]]
"""

##

[[stack]]
name = "passbolt"
tags = ["komodo-1", "identity", "external"]
[stack.config]
server = "komodo-1"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  db:
    image: mariadb:10.11
    restart: unless-stopped
    env_file:
      - .env
    environment:
      MYSQL_RANDOM_ROOT_PASSWORD: "true"
    volumes:
      - database_volume:/var/lib/mysql

  passbolt:
    image: passbolt/passbolt:latest-ce
    #Alternatively you can use rootless:
    #image: passbolt/passbolt:latest-ce-non-root
    restart: unless-stopped
    networks:
      - default
      - d3internal
    depends_on:
      - db
    env_file:
      - .env
    volumes:
      - gpg_volume:/etc/passbolt/gpg
      - jwt_volume:/etc/passbolt/jwt
    command:
      [
        "/usr/bin/wait-for.sh",
        "-t",
        "0",
        "db:3306",
        "--",
        "/docker-entrypoint.sh",
      ]
    ports:
      - 8783:80
      - 444:443
    #Alternatively for non-root images:
    # - 80:8080
    # - 443:4433

volumes:
  database_volume:
  gpg_volume:
  jwt_volume:
"""
environment = """
APP_FULL_BASE_URL: https://passbolt.d3adc3ii.cc
MYSQL_DATABASE: "d3passbolt"
MYSQL_USER: "d3bolt"
MYSQL_PASSWORD: ";05SX|EXiXPf$r^crV46bIIBGe;4*DcWB^ZHvULYODlsjpoiisf_EUHQ3}X^1-x"
DATASOURCES_DEFAULT_HOST: "db"
DATASOURCES_DEFAULT_USERNAME: "d3bolt"
DATASOURCES_DEFAULT_PASSWORD: ";05SX|EXiXPf$r^crV46bIIBGe;4*DcWB^ZHvULYODlsjpoiisf_EUHQ3}X^1-x"
DATASOURCES_DEFAULT_DATABASE: "d3passbolt"

EMAIL_DEFAULT_FROM_NAME='Passbolt'
EMAIL_DEFAULT_FROM='no-reply@d3adc3ii.cc'
EMAIL_TRANSPORT_DEFAULT_HOST='mail.smtp2go.com'
EMAIL_TRANSPORT_DEFAULT_USERNAME='d3adc3ii.cc'
EMAIL_TRANSPORT_DEFAULT_PASSWORD='taolavodich1234'
EMAIL_TRANSPORT_DEFAULT_PORT=2525
EMAIL_TRANSPORT_DEFAULT_TLS=yes


"""

##

[[stack]]
name = "phpipam"
tags = ["internal", "komodo-3"]
[stack.config]
server = "komodo-3"
project_name = "phpipam"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  phpipam-web:
    image: phpipam/phpipam-www:latest
    ports:
      - "8087:80"
    restart: always
    env_file:
      - .env
    volumes:
      - ${DOCKER_DATA}/phpipam/logo:/phpipam/css/images/logo
      - ${DOCKER_DATA}/phpipam/ca:/usr/local/share/ca-certificates:ro
    depends_on:
      - phpipam-mariadb
    labels:
      proxy.aliases: phpipam

  phpipam-cron:
    image: phpipam/phpipam-cron:latest
    env_file:
      - .env
    restart: always
    volumes:
      - ${DOCKER_DATA}/phpipam/ca:/usr/local/share/ca-certificates:ro
    depends_on:
      - phpipam-mariadb

  phpipam-mariadb:
    image: mariadb:latest
    env_file:
      - .env
    restart: always
    volumes:
      - /etc/komodo/stacks/phpipam/db:/var/lib/mysql
"""
environment = """
PUID=1000
PGID=1000
TZ=Asia/Singapore
IPAM_DATABASE_HOST=phpipam-mariadb
#IPAM_DATABASE_PASS=GnH&dXUVth5LEeItTTGQvds
IPAM_DATABASE_PASS=password
IPAM_DATABASE_WEBHOST=%

IPAM_TRUST_X_FORWARDED=true
SCAN_INTERVAL=1h
MYSQL_ROOT_PASSWORD=16E@j4pWjtL$X3Gnxfy3KQB0U$
"""

##

[[stack]]
name = "piped"
tags = ["komodo-2", "external"]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
    frontend:
        image: 1337kavin/piped-frontend:latest
        restart: unless-stopped
        depends_on:
            - piped
        environment:
            BACKEND_HOSTNAME: pipedapi.d3adc3ii.cc
            HTTP_MODE: https
        ports:
            - "8080:80"
        container_name: piped-frontend

    piped:
        image: 1337kavin/piped:latest
        restart: unless-stopped
        environment:
          - PUID=1000
          - PGID=1000
        volumes:
          #  - ./config/config.properties:/app/config.properties:ro
            - ${DOCKER_DATA}/piped/config/config.properties:/app/config.properties:ro
        depends_on:
            - postgres
        ports:
            - "8081:8080"
        container_name: piped-backend

    proxy:
        image: 1337kavin/piped-proxy:latest
        restart: unless-stopped
        ports:
            - "8082:8080"
        container_name: piped-proxy

    bg-helper:
        image: 1337kavin/bg-helper-server:latest
        restart: unless-stopped
        container_name: piped-bg-helper

    postgres:
        image: pgautoupgrade/pgautoupgrade:16-alpine
        restart: unless-stopped
        volumes:
            - ./data/db:/var/lib/postgresql/data
        env_file:
            - .env
        container_name: piped-postgres
"""
environment = """
POSTGRES_DB=piped
POSTGRES_USER=piped
POSTGRES_PASSWORD='F2dv9HNbOImHGxNO2lhD304XwRr7GMSl'
"""

##

[[stack]]
name = "prowlarr"
tags = ["internal", "komodo-2"]
[stack.config]
server = "komodo-2"
links = [
  "https://prowlarr.d3adc3ii.site/"
]
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  prowlarr:
    image: lscr.io/linuxserver/prowlarr:latest
    container_name: prowlarr
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Singapore
    volumes:
      - ${DOCKER_DATA}/prowlarr/data:/config
    ports:
      - 9696:9696
    restart: unless-stopped
    labels:
      proxy.idle_timeout: 1h
"""

##

[[stack]]
name = "scrutiny"
tags = ["komodo-3"]
[stack.config]
server = "komodo-3"
links = [
  "https://scrutiny.d3adc3ii.cc/web/dashboard"
]
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  scrutiny-monitoring: # A common network for all monitoring services to communicate into
    external: true
  scrutiny-notification: # To Gotify or another Notification service
    external: true

services:
  influxdb:
    container_name: influxdb
    image: influxdb:2.1-alpine
    env_file:
      - .env
    user: 1000:1000
    ports:
      - 8086:8086
    volumes:
      - ${DOCKER_DATA}/scrutiny/influxdb2/db:/var/lib/influxdb2
      - ${DOCKER_DATA}/scrutiny/influxdb2/config:/etc/influxdb2
    restart: unless-stopped
    networks:
      - scrutiny-monitoring

  scrutiny:
    container_name: scrutiny
    image: ghcr.io/analogj/scrutiny:master-web
    ports:
      - 8785:8080
    volumes:
      - ${DOCKER_DATA}/scrutiny/config:/opt/scrutiny/config
    env_file:
      - .env
      # Optional but highly recommended to notify you in case of a problem
     # - SCRUTINY_NOTIFY_URLS=["http://gotify:80/message?token=a-gotify-token"]
    depends_on:
      - influxdb
    restart: unless-stopped
    networks:
      - scrutiny-notification
      - scrutiny-monitoring
"""
environment = """
PGID= 1000 
PUID= 1000
DOCKER_INFLUXDB_INIT_MODE=setup
DOCKER_INFLUXDB_INIT_USERNAME=Admin
DOCKER_INFLUXDB_INIT_PASSWORD= 'qA6otE2(raC=MDh$ZN%tNulHp6iYs|xv}l&IwVWPzZvn+Tvm399+2w#V$P'
#DOCKER_INFLUXDB_INIT_PASSWORD= [[SCRUTINY_DOCKER_INFLUXDB_INIT_PASSWORD]]
DOCKER_INFLUXDB_INIT_ORG=homelab
DOCKER_INFLUXDB_INIT_BUCKET=scrutiny
DOCKER_INFLUXDB_INIT_ADMIN_TOKEN= '6-zG/W<%eE-)rG6Gh9@WY^v#+y3KN()tf2}UNkXN=j{lDnu+P7+Kl!$G<(x['
#DOCKER_INFLUXDB_INIT_ADMIN_TOKEN= [[SCRUTINY_DOCKER_INFLUXDB_INIT_ADMIN_TOKEN]]
SCRUTINY_WEB_INFLUXDB_HOST=influxdb
SCRUTINY_WEB_INFLUXDB_PORT=8086
SCRUTINY_WEB_INFLUXDB_TOKEN= '6-zG/W<%eE-)rG6Gh9@WY^v#+y3KN()tf2}UNkXN=j{lDnu+P7+Kl!$G<(x['
#SCRUTINY_WEB_INFLUXDB_TOKEN= [[SCRUTINY_WEB_INFLUXDB_TOKEN]]
SCRUTINY_WEB_INFLUXDB_ORG=homelab
SCRUTINY_WEB_INFLUXDB_BUCKET=scrutiny
"""

##

[[stack]]
name = "selfhst-icons"
[stack.config]
server = "komodo-3"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  selfhst-icons:
    image: ghcr.io/selfhst/icons:latest
    restart: unless-stopped
    ports:
      - 4050:4050
    labels:
      proxy.idle_timeout: 10m
"""

##

[[stack]]
name = "shellhub"
[stack.config]
server = "komodo-1"
project_name = "shellhub"
files_on_host = true
run_directory = "/home/d3/shellhub"
file_paths = [
  "docker-compose.agent.yml",
  "docker-compose.autossl.yml",
  "docker-compose.dev.yml",
  "docker-compose.enterprise.yml",
  "docker-compose.test.yml",
  "docker-compose.yml"
]

##

[[stack]]
name = "silverbullet"
tags = ["external", "komodo-2"]
[stack.config]
server = "komodo-2"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
services:
  silverbullet:
    image: ghcr.io/silverbulletmd/silverbullet:v2
    container_name: silverbullet
    restart: unless-stopped
    env_file:
      - .env
    volumes:
      - ${DOCKER_DATA}/silverbullet/space:/space
    ports:
      - 3718:3000
    labels:
      proxy.exclude: true
"""
environment = """
SB_USER=[[SILVERBULLET_USER]]
PGID=1000
PUID=1000
"""

##

[[stack]]
name = "stashapp"
tags = ["komodo-2"]
[stack.config]
server = "komodo-2"
links = ["https://stash.d3adc3ii.site"]
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
# APPNICENAME=Stash
# APPDESCRIPTION=An organizer for your porn, written in Go
services:
  stash:
    image: stashapp/stash:latest
    container_name: stash
    restart: unless-stopped
    ## the container's port must be the same with the STASH_PORT in the environment section
    ports:
      - "9999:9999"
    ## If you intend to use stash's DLNA functionality uncomment the below network mode and comment out the above ports section
    # network_mode: host
    logging:
      driver: "json-file"
      options:
        max-file: "10"
        max-size: "2m"
    env_file:
      - .env
    environment:
      - PUID=1000
      - PGID=1000
      - STASH_STASH=/data/
      - STASH_GENERATED=/generated/
      - STASH_METADATA=/metadata/
      - STASH_CACHE=/cache/
      ## Adjust below to change default port (9999)
      - STASH_PORT=9999
    volumes:
      - /etc/localtime:/etc/localtime:ro
      ## Adjust below paths (the left part) to your liking.
      ## E.g. you can change ./config:/root/.stash to ./stash:/root/.stash
      ## The left part is the path on your host, the right part is the path in the stash container.

      ## Keep configs, scrapers, and plugins here.
      - ${DOCKER_DATA}/stashapp/config:/root/.stash
      ## Point this at your collection./stashapp/config
      ## The left side is where your collection is on your host, the right side is where it will be in stash.
      - ${VAULT}/vault:/data
      ## This is where your stash's metadata lives
      - ${DOCKER_DATA}/stashapp/metadata:/metadata
      ## Any other cache content.
      - ${DOCKER_DATA}stashapp/cache:/cache
      ## Where to store binary blob data (scene covers, images)
      - ${DOCKER_DATA}/stashapp/blobs:/blobs
      ## Where to store generated content (screenshots,previews,transcodes,sprites)
      -  ${DOCKER_DATA}stashapp/generated:/generated
    labels:
      - homepage.group=Media
      - homepage.name=Stash
      - homepage.icon=sh-stashapp-light
      - homepage.href=https://stash.d3adc3ii.site
      #- homepage.widget.type=
      #- homepage.widget.widget.url=
      #- homepage.widget.stashapikey=
"""
environment = """
VAULT=/mnt/zFiles
"""

##

[[stack]]
name = "termix"
[stack.config]
server = "komodo-1"
links = ["https://termix.d3adc3ii.cc"]
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  termix:
    image: ghcr.io/lukegus/termix:latest
    container_name: termix
    restart: unless-stopped
    networks:
      - d3internal
    ports:
      - "8282:8080"
    volumes:
      - ${DOCKER_DATA}/termix/data:/app/data
    env_file:
      - .env
    labels:
      - homepage.group=Access
      - homepage.name=Termix
      - homepage.icon=sh-termix-light
      - homepage.href=https://termix.d3adc3ii.cc
"""
environment = """
SALT: "tJ,V_^12phQ=66k'<v*7G?-Qw:/o)dom"
PORT: "8080"
"""

##

[[stack]]
name = "true-command"
tags = ["komodo-28"]
[stack.config]
server = "komodo-28"
file_contents = """
services:
  true-command:
    container_name: true-command
    image: ixsystems/truecommand:latest
    restart: unless-stopped
    volumes:
      - ${DOCKER_DATA}/truecommand:/data
    ports:
      - 8880:80
      - 4443:443
    labels:  
      proxy.idle_timeout: 15m
"""

##

[[stack]]
name = "uptime-kuma"
tags = [
  "external",
  "monitoring",
  "komodo-3"
]
[stack.config]
server = "komodo-28"
links = ["https://uptime.d3adc3ii.cc/"]
project_name = "uptime-kuma"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  uptime-kuma:
    image: louislam/uptime-kuma:1
    container_name: uptime-kuma
    networks: 
      - d3internal
    env_file:
      - .env
    volumes:
      - ${DOCKER_DATA}/uptime-kuma/data:/app/data
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 3111:3001
    restart: always
    labels:
      - homepage.group=Monitor
      - homepage.name=Uptime Kuma
      - homepage.icon=sh-uptime-kuma-light
      - homepage.href=https://uptime.d3adc3ii.cc/
      - homepage.widget.type=uptimekuma
      - homepage.widget.url=https://uptime.d3adc3ii.cc
      - homepage.widget.slug=ping
"""
environment = """
PUID=1000
PGID=1000
"""

##

[[stack]]
name = "wallos"
tags = [
  "external",
  "production",
  "komodo-3"
]
[stack.config]
server = "komodo-28"
poll_for_updates = true
auto_update = true
auto_update_all_services = true
file_contents = """
networks:
  d3internal:
    external: true
services:
  wallos:
    container_name: wallos
    image: bellamy/wallos:latest
    networks:
      - d3internal
    ports:
      - "8282:80/tcp"
    env_file:
      - .env
    volumes:
      - ${DATA_DIR}/db:/var/www/html/db'
      - ${DATA_DIR}/logos:/var/www/html/images/uploads/logos'
    restart: unless-stopped
    labels:
      - homepage.group=Applications
      - homepage.name=Wallos
      - homepage.icon=sh-wallos-light
      - homepage.href=https://wallos.d3adc3ii.cc
"""
environment = """
TZ= 'Asia/Singapore'
DATA_DIR=/mnt/zApps/wallos
PUID=1000
PGID=1000
"""

##

[[deployment]]
name = "apprise"
[deployment.config]
server = "komodo-3"
image.type = "Image"
image.params.image = "caronc/apprise:latest"
poll_for_updates = true
auto_update = true
network = "bridge"
ports = """
8000:8000
"""
volumes = """
/mnt/zApps/apprise_api/config:/opt/apprise/config
/mnt/zApps/apprise_api/plugin:/opt/apprise/plugin
/mnt/zApps/apprise_api/attach:/opt/apprise/attach
"""
environment = """
PUID=1000
PGID=1000
APPRISE_STATEFUL_MODE=simple
APPRISE_WORKER_COUNT=1
"""

##

[[deployment]]
name = "nessus"
tags = ["internal", "testing"]
[deployment.config]
server = "komodo-2"
image.type = "Image"
image.params.image = "tenable/nessus:latest-ubuntu"

##

[[deployment]]
name = "newt1"
tags = ["external", "production"]
[deployment.config]
server = "komodo-1"
image.type = "Image"
image.params.image = "fosrl/newt"
poll_for_updates = true
auto_update = true
restart = "unless-stopped"
environment = """
  PANGOLIN_ENDPOINT=https://pangolin.d3adc3ii.cc
  NEWT_ID=[[NEWT_ID1]]
  NEWT_SECRET=[[NEWT_SECRET1]]
"""

##

[[deployment]]
name = "statementsensei"
tags = ["internal", "testing"]
[deployment.config]
server = "komodo-2"
image.type = "Image"
image.params.image = "benjaminawd/statementsensei:latest"
poll_for_updates = true
auto_update = true
network = "bridge"
ports = """
8501:8501
"""
environment = """
  PDF_PASSWORD= [[PDF_PASSWORD]]
"""
labels = """
caddy: statement.d3adc3ii.site
caddy.reverse_proxy: "{{upstreams 8501}}"
"""

##

[[deployment]]
name = "twingate"
tags = ["external", "production"]
[deployment.config]
server = "komodo-2"
image.type = "Image"
image.params.image = "twingate/connector:latest"
poll_for_updates = true
auto_update = true
restart = "unless-stopped"
environment = """
  TWINGATE_NETWORK=d3net
  TWINGATE_ACCESS_TOKEN=eyJhbGciOiJFUzI1NiIsImtpZCI6Inp3dkU1dHpJZzV4X2pSVEU4RTFWQll6MW0tX2g1dXlMZlhTV1VSS1BEVE0iLCJ0eXAiOiJEQVQifQ.eyJudCI6IkFOIiwiYWlkIjoiNTExMjE5IiwiZGlkIjoiMjE5MTEwMCIsImp0aSI6ImIxZjU3N2FkLTZmNDItNDYyYS05ZGIzLTY1NTE5ZmQyMTJlNCIsImlzcyI6InR3aW5nYXRlIiwiYXVkIjoiZDNuZXQiLCJleHAiOjE3NDYxNDQ5MDAsImlhdCI6MTc0NjE0MTMwMCwidmVyIjoiNCIsInRpZCI6IjEwMzU2NCIsInJudyI6MTc0NjE0MTU3OCwicm5ldGlkIjoiMTM1OTMxIn0.OxT4qXnqonLPGb1GwJTRcYoSwZG16x2JGA_Xu2pOo0dZH3jpqfd1SkjWy8JjcVePboTum2e0WEdNu4SFcJUy_A
  TWINGATE_REFRESH_TOKEN=mrNJNc7hirY3gO3-q9l6dnN_YjYl-8q79XRXg1ffZstYm8EYyH6xNXMIVviMaQ-2-GAa4wuSMv1J5ebEf9KvzIK94jmq7j9QGPH2Tr7ZnjlYADuKrEpKUkrmnbrROkgQy6nzWg
  TWINGATE_LOG_ANALYTICS=v2
"""

##

[[repo]]
name = "diiihl"
[repo.config]
server = "komodo-1"
builder = "local"
git_account = "d3hl"
repo = "d3hl/dIIIhl"

##

[[repo]]
name = "diiihl-3"
[repo.config]
server = "komodo-3"
builder = "local"
git_account = "d3hl"
repo = "d3hl/dIIIhl"

##

[[procedure]]
name = "pull repo and deploy homepage"

[[procedure.config.stage]]
name = "pull repo and destroy stack"
enabled = true
executions = [
  { execution.type = "PullRepo", execution.params.repo = "diiihl", enabled = true },
  { execution.type = "DestroyStack", execution.params.stack = "homepage", execution.params.services = [], execution.params.remove_orphans = false, enabled = true }
]

[[procedure.config.stage]]
name = "Stage 3"
enabled = true
executions = [
  { execution.type = "DeployStack", execution.params.stack = "homepage", execution.params.services = [], enabled = true }
]

[[procedure.config.stage]]
name = "Stage 4"
enabled = false
executions = [
  { execution.type = "CommitSync", execution.params.sync = "sync", enabled = false }
]

##

[[alerter]]
name = "discord-webhook"
[alerter.config]
enabled = true
endpoint.type = "Custom"
endpoint.params.url = "http://10.10.10.26:7000"
alert_types = [
  "ServerUnreachable",
  "ServerMem",
  "ServerCpu",
  "ServerDisk",
  "StackAutoUpdated",
  "StackStateChange",
  "ContainerStateChange",
  "StackImageUpdateAvailable",
  "DeploymentAutoUpdated",
  "DeploymentImageUpdateAvailable",
  "ResourceSyncPendingUpdates",
  "AwsBuilderTerminationFailed",
  "BuildFailed",
  "RepoBuildFailed"
]

##

[[builder]]
name = "local"
[builder.config]
type = "Server"
params.server_id = "komodo-1"

##

[[resource_sync]]
name = "sync"
[resource_sync.config]
repo = "d3hl/dIIIhl"
git_account = "d3hl"
resource_path = ["komodo/resources/main.toml"]
managed = true
include_user_groups = true

##

[[resource_sync]]
name = "var"
[resource_sync.config]
repo = "d3hl/dIIIhl"
git_account = "d3hl"
resource_path = ["komodo/resources/var.toml"]
managed = true
include_resources = false
include_variables = true